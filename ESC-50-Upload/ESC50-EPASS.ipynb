{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70dc3c6-338d-4a9e-bcd1-3bfb870347c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-100032-A-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-100038-A-14.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-100210-A-36.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "      <td>ESC-50-master/audio/1-100210-B-36.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-101296-A-19.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take  \\\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A   \n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A   \n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A   \n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B   \n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A   \n",
       "\n",
       "                                filepath  \n",
       "0   ESC-50-master/audio/1-100032-A-0.wav  \n",
       "1  ESC-50-master/audio/1-100038-A-14.wav  \n",
       "2  ESC-50-master/audio/1-100210-A-36.wav  \n",
       "3  ESC-50-master/audio/1-100210-B-36.wav  \n",
       "4  ESC-50-master/audio/1-101296-A-19.wav  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load CSV metadata\n",
    "meta_df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "# Add full path to audio files\n",
    "meta_df['filepath'] = meta_df['filename'].apply(lambda x: os.path.join('ESC-50-master/audio/', x))\n",
    "\n",
    "# Display sample\n",
    "meta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3010c5-5c4e-4a09-b247-f2d651067c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audiomentations\n",
      "  Downloading audiomentations-0.40.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from audiomentations) (1.26.4)\n",
      "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
      "  Downloading numpy_minmax-0.4.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
      "  Downloading numpy_rms-0.5.0-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from audiomentations) (0.10.2.post1)\n",
      "Collecting python-stretch<1,>=0.3.1 (from audiomentations)\n",
      "  Downloading python_stretch-0.3.1-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: scipy<2,>=1.4 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from audiomentations) (1.10.1)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from audiomentations) (0.5.0.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.13.0)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\n",
      "INFO: pip is looking at multiple versions of numpy-minmax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
      "  Downloading numpy_minmax-0.3.1-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "INFO: pip is looking at multiple versions of numpy-rms to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
      "  Downloading numpy_rms-0.4.2-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.22)\n",
      "Requirement already satisfied: packaging in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (23.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2024.12.14)\n",
      "Downloading audiomentations-0.40.0-py3-none-any.whl (83 kB)\n",
      "Downloading numpy_minmax-0.3.1-cp310-cp310-win_amd64.whl (14 kB)\n",
      "Downloading numpy_rms-0.4.2-cp310-cp310-win_amd64.whl (13 kB)\n",
      "Downloading python_stretch-0.3.1-cp310-cp310-win_amd64.whl (98 kB)\n",
      "Installing collected packages: python-stretch, numpy-rms, numpy-minmax, audiomentations\n",
      "Successfully installed audiomentations-0.40.0 numpy-minmax-0.3.1 numpy-rms-0.4.2 python-stretch-0.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Arnav\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bcf476-56ad-46c8-8019-fc0f104699db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, Gain\n",
    "\n",
    "class ESC50Dataset(Dataset):\n",
    "    def __init__(self, df, sample_rate=44100, duration=5.0, augment_type='none', n_mels=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sr = sample_rate\n",
    "        self.length = int(sample_rate * duration)\n",
    "        self.augment_type = augment_type\n",
    "        self.n_mels = n_mels\n",
    "\n",
    "        self.weak_transform = Compose([\n",
    "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        ])\n",
    "        self.strong_transform = Compose([\n",
    "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.02, p=0.5),\n",
    "            PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "            TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            Gain(min_gain_db=-6, max_gain_db=6, p=0.5)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = row['filepath']\n",
    "        label = row['target'] if 'target' in row else -1\n",
    "\n",
    "        y, _ = librosa.load(path, sr=self.sr)\n",
    "        if len(y) < self.length:\n",
    "            y = np.pad(y, (0, self.length - len(y)))\n",
    "        else:\n",
    "            y = y[:self.length]\n",
    "\n",
    "        if self.augment_type == 'weak':\n",
    "            y = self.weak_transform(samples=y, sample_rate=self.sr)\n",
    "        elif self.augment_type == 'strong':\n",
    "            y = self.strong_transform(samples=y, sample_rate=self.sr)\n",
    "\n",
    "        # Convert to Mel spectrogram\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=self.sr, n_mels=self.n_mels)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "        # Normalize and convert to torch tensor [1, H, W]\n",
    "        mel_tensor = torch.tensor(mel_db, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return mel_tensor, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d36b542-716e-4bb9-8463-e0bbce9a46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labeled_unlabeled_and_save(df, labeled_fraction=0.1, save_dir=\"labeled-unlabeled\"):\n",
    "    import os\n",
    "    os.makedirs(f'{save_dir}/{labeled_fraction}', exist_ok=True)\n",
    "\n",
    "    labeled_df_list = []\n",
    "    unlabeled_df_list = []\n",
    "\n",
    "    for label in sorted(df['target'].unique()):\n",
    "        class_df = df[df['target'] == label]\n",
    "        n_total = len(class_df)\n",
    "        n_labeled = max(1, int(n_total * labeled_fraction))\n",
    "\n",
    "        labeled = class_df.sample(n=n_labeled, random_state=42)\n",
    "        unlabeled = class_df.drop(labeled.index)\n",
    "\n",
    "        labeled_df_list.append(labeled)\n",
    "        unlabeled_df_list.append(unlabeled)\n",
    "\n",
    "    labeled_df = pd.concat(labeled_df_list).reset_index(drop=True)\n",
    "    unlabeled_df = pd.concat(unlabeled_df_list).reset_index(drop=True)\n",
    "\n",
    "    # Drop label/category from the unlabeled set\n",
    "    unlabeled_df = unlabeled_df.drop(columns=[\"target\", \"category\"])\n",
    "\n",
    "    labeled_df.head()\n",
    "    unlabeled_df.head()\n",
    "    \n",
    "    # Save both\n",
    "    labeled_df.to_csv(f\"{save_dir}/{labeled_fraction}/labeled.csv\", index=False)      # with labels\n",
    "    unlabeled_df.to_csv(f\"{save_dir}/{labeled_fraction}/unlabeled.csv\", index=False)  # without labels\n",
    "\n",
    "    print(f\"Saved labeled.csv (with labels) and unlabeled.csv (no labels) to '{save_dir}/{labeled_fraction}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bef9656-fac8-4a84-84dc-98003a29c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_ssl_loaders(meta_df,labeled_fraction=0.1, fold=1, batch_size=16, split_dir=\"labeled-unlabeled\"):\n",
    "    # Load pre-saved labeled and unlabeled CSVs for this fold\n",
    "    labeled_df = pd.read_csv(f\"{split_dir}/{labeled_fraction}/labeled.csv\")\n",
    "    unlabeled_df = pd.read_csv(f\"{split_dir}/{labeled_fraction}/unlabeled.csv\")\n",
    "\n",
    "    # Get validation set from meta_df\n",
    "    val_df = meta_df[meta_df['fold'] == fold]\n",
    "\n",
    "    # Create datasets\n",
    "    labeled_dataset = ESC50Dataset(labeled_df, augment_type='weak')\n",
    "    unlabeled_dataset = DualViewESC50Dataset(unlabeled_df)\n",
    "    val_dataset = ESC50Dataset(val_df, augment_type='none')\n",
    "\n",
    "    # Create loaders\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    return labeled_loader, unlabeled_loader, val_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6805eba-acfe-4937-bd33-e42017466ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved labeled.csv (with labels) and unlabeled.csv (no labels) to 'labeled-unlabeled/0.2'\n"
     ]
    }
   ],
   "source": [
    "labeled_fraction = 0.2\n",
    "split_labeled_unlabeled_and_save(\n",
    "    meta_df,\n",
    "    labeled_fraction=labeled_fraction,\n",
    "    save_dir=\"labeled-unlabeled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5bf078-bbdb-4894-b179-f25c6542a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualViewESC50Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.weak_dataset = ESC50Dataset(df, augment_type='weak')\n",
    "        self.strong_dataset = ESC50Dataset(df, augment_type='strong')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.weak_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        weak_x, _ = self.weak_dataset[idx]\n",
    "        strong_x, _ = self.strong_dataset[idx]\n",
    "        return weak_x, strong_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113e94a5-f6b5-417f-bdfb-7952de413140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class BasicBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=9, pool_size=4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(pool_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResNet1DAudioEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18\n",
    "        base_model = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Modify first conv layer to accept 1-channel input instead of 3\n",
    "        base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Remove final classification layer and get features\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])  # [B, 512, 1, 1]\n",
    "\n",
    "        # Final linear layer to project into embedding space\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Flatten(),               # → [B, 512]\n",
    "            nn.Linear(512, embed_dim),  # → [B, embed_dim]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Expects input x: [B, 1, H, W] — e.g., Mel spectrogram\n",
    "        \"\"\"\n",
    "        x = self.feature_extractor(x)         # [B, 512, 1, 1]\n",
    "        x = self.projection(x)                # [B, embed_dim]\n",
    "        return x\n",
    "\n",
    "\n",
    "class EPASSProjectors(nn.Module):\n",
    "    def __init__(self, embed_dim=256, proj_dim=128, num_proj=3):\n",
    "        super().__init__()\n",
    "        self.projectors = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(embed_dim, proj_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(proj_dim, proj_dim)\n",
    "            ) for _ in range(num_proj)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        projections = [proj(x) for proj in self.projectors]\n",
    "        ensemble = torch.stack(projections).mean(dim=0)  # Mean ensemble\n",
    "        return ensemble, projections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ddd519-6916-4d7e-95a0-59c1462809a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_one_epoch(encoder, projectors, classifier, labeled_loader, unlabeled_loader, optimizer, device, epoch, confidence_thresh=0.95):\n",
    "    encoder.train()\n",
    "    projectors.train()\n",
    "    classifier.train()\n",
    "\n",
    "    total_loss, total_ce, total_uloss, total_closs = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    unlabeled_iter = iter(unlabeled_loader)\n",
    "\n",
    "    for (x_l, y_l) in labeled_loader:\n",
    "        # Get one batch from unlabeled loader\n",
    "        try:\n",
    "            xw, xs = next(unlabeled_iter)\n",
    "        except StopIteration:\n",
    "            unlabeled_iter = iter(unlabeled_loader)\n",
    "            xw, xs = next(unlabeled_iter)\n",
    "\n",
    "        x_l, y_l = x_l.to(device), y_l.to(device)\n",
    "        xw, xs = xw.to(device), xs.to(device)\n",
    "\n",
    "        # ---- Forward ----\n",
    "        embed_l = encoder(x_l)       # [B, 256]\n",
    "        embed_w = encoder(xw)        # [B, 256]\n",
    "        embed_s = encoder(xs)        # [B, 256]\n",
    "\n",
    "        # Classifier\n",
    "        logits_l = classifier(embed_l)\n",
    "        logits_w = classifier(embed_w)\n",
    "        logits_s = classifier(embed_s)\n",
    "\n",
    "        # Supervised CE Loss\n",
    "        ce_loss = F.cross_entropy(logits_l, y_l)\n",
    "\n",
    "        # Pseudo-labels\n",
    "        probs_w = torch.softmax(logits_w.detach(), dim=1)\n",
    "        max_probs, pseudo_labels = torch.max(probs_w, dim=1)\n",
    "        mask = (max_probs >= confidence_thresh).float()\n",
    "\n",
    "        uloss = F.cross_entropy(logits_s, pseudo_labels, reduction='none')\n",
    "        uloss = (uloss * mask).mean()\n",
    "\n",
    "        # ---- EPASS: Contrastive Loss ----\n",
    "        ens_w, _ = projectors(embed_w)\n",
    "        ens_s, _ = projectors(embed_s)\n",
    "\n",
    "        # Normalize\n",
    "        ens_w = F.normalize(ens_w, dim=1)\n",
    "        ens_s = F.normalize(ens_s, dim=1)\n",
    "\n",
    "        # Cosine sim loss\n",
    "        sim = (ens_w * ens_s).sum(dim=1)\n",
    "        closs = -torch.log(sim + 1e-6).mean()\n",
    "\n",
    "        # ---- Total loss ----\n",
    "        loss = ce_loss + uloss + 0.5 * closs\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_ce += ce_loss.item()\n",
    "        total_uloss += uloss.item()\n",
    "        total_closs += closs.item()\n",
    "\n",
    "    print(f\"  Pseudo-labels used: {mask.sum().item()} / {mask.shape[0]}\")\n",
    "    print(f\"[Epoch {epoch}] Loss: {total_loss:.4f} | CE: {total_ce:.4f} | U: {total_uloss:.4f} | Contrastive: {total_closs:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df378b5-0cde-4168-ae38-fee163e712ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(encoder, classifier, val_loader, device, num_classes=50, plot_loss_curves=False, train_losses=None, val_losses=None):\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = classifier(encoder(x))\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # print(f\"\\nValidation Accuracy: {acc:.2f}%\")\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    # Core metrics\n",
    "    precision = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # AUC-PRC\n",
    "    try:\n",
    "        auc_prc = average_precision_score(\n",
    "            y_true=np.eye(num_classes)[all_labels],\n",
    "            y_score=all_probs,\n",
    "            average=\"macro\"\n",
    "        )\n",
    "        print(f\"AUC-PRC (macro): {auc_prc:.4f}\")\n",
    "    except Exception as e:\n",
    "        auc_prc = None\n",
    "        print(f\"AUC-PRC: Not computable — {str(e)}\")\n",
    "\n",
    "    # AUC-ROC\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(\n",
    "            y_true=np.eye(num_classes)[all_labels],\n",
    "            y_score=all_probs,\n",
    "            average=\"macro\",\n",
    "            multi_class='ovr'\n",
    "        )\n",
    "        print(f\"AUC-ROC (macro): {auc_roc:.4f}\")\n",
    "    except Exception as e:\n",
    "        auc_roc = None\n",
    "        print(f\"AUC-ROC: Not computable — {str(e)}\")\n",
    "\n",
    "    # Optional: Plot Loss Curves\n",
    "    if plot_loss_curves and train_losses and val_losses:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Train vs Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Return all stats\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"auc_prc\": auc_prc,\n",
    "        \"auc_roc\": auc_roc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06890f6-6732-41d4-a034-92b27000d291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 1] Loss: 98.5026 | CE: 97.8990 | U: 0.4654 | Contrastive: 0.2765\n",
      "AUC-PRC (macro): 0.1757\n",
      "AUC-ROC (macro): 0.7978\n",
      "Validation Accuracy: 10.75%\n",
      "Saved best model for Fold 2 at epoch 1\n",
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 2] Loss: 84.0869 | CE: 83.8346 | U: 0.2412 | Contrastive: 0.0222\n",
      "AUC-PRC (macro): 0.1538\n",
      "AUC-ROC (macro): 0.8013\n",
      "Validation Accuracy: 9.00%\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 3] Loss: 78.0266 | CE: 77.4651 | U: 0.5585 | Contrastive: 0.0059\n",
      "AUC-PRC (macro): 0.2332\n",
      "AUC-ROC (macro): 0.8355\n",
      "Validation Accuracy: 17.00%\n",
      "Saved best model for Fold 2 at epoch 3\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 4] Loss: 70.2874 | CE: 69.5162 | U: 0.7690 | Contrastive: 0.0042\n",
      "AUC-PRC (macro): 0.3454\n",
      "AUC-ROC (macro): 0.8906\n",
      "Validation Accuracy: 28.50%\n",
      "Saved best model for Fold 2 at epoch 4\n",
      "  Pseudo-labels used: 2.0 / 16\n",
      "[Epoch 5] Loss: 64.4344 | CE: 62.9396 | U: 1.4934 | Contrastive: 0.0029\n",
      "AUC-PRC (macro): 0.3548\n",
      "AUC-ROC (macro): 0.8982\n",
      "Validation Accuracy: 25.50%\n",
      "  Pseudo-labels used: 3.0 / 16\n",
      "[Epoch 6] Loss: 59.5127 | CE: 57.4842 | U: 2.0278 | Contrastive: 0.0016\n",
      "AUC-PRC (macro): 0.4188\n",
      "AUC-ROC (macro): 0.9198\n",
      "Validation Accuracy: 34.25%\n",
      "Saved best model for Fold 2 at epoch 6\n",
      "  Pseudo-labels used: 4.0 / 16\n",
      "[Epoch 7] Loss: 63.0146 | CE: 59.3565 | U: 3.6571 | Contrastive: 0.0020\n",
      "AUC-PRC (macro): 0.3911\n",
      "AUC-ROC (macro): 0.9099\n",
      "Validation Accuracy: 30.25%\n",
      "  Pseudo-labels used: 2.0 / 16\n",
      "[Epoch 8] Loss: 56.6154 | CE: 53.1639 | U: 3.4506 | Contrastive: 0.0020\n",
      "AUC-PRC (macro): 0.4210\n",
      "AUC-ROC (macro): 0.9239\n",
      "Validation Accuracy: 31.75%\n",
      "  Pseudo-labels used: 6.0 / 16\n",
      "[Epoch 9] Loss: 55.9059 | CE: 51.5374 | U: 4.3678 | Contrastive: 0.0014\n",
      "AUC-PRC (macro): 0.4010\n",
      "AUC-ROC (macro): 0.9343\n",
      "Validation Accuracy: 31.25%\n",
      "  Pseudo-labels used: 6.0 / 16\n",
      "[Epoch 10] Loss: 47.4870 | CE: 42.7280 | U: 4.7584 | Contrastive: 0.0011\n",
      "AUC-PRC (macro): 0.4983\n",
      "AUC-ROC (macro): 0.9417\n",
      "Validation Accuracy: 39.25%\n",
      "Saved best model for Fold 2 at epoch 10\n",
      "  Pseudo-labels used: 3.0 / 16\n",
      "[Epoch 11] Loss: 47.6495 | CE: 41.3569 | U: 6.2921 | Contrastive: 0.0010\n",
      "AUC-PRC (macro): 0.4670\n",
      "AUC-ROC (macro): 0.9367\n",
      "Validation Accuracy: 37.25%\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 12] Loss: 44.8780 | CE: 38.2289 | U: 6.6487 | Contrastive: 0.0009\n",
      "AUC-PRC (macro): 0.4975\n",
      "AUC-ROC (macro): 0.9318\n",
      "Validation Accuracy: 37.25%\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 13] Loss: 48.3367 | CE: 41.4181 | U: 6.9183 | Contrastive: 0.0007\n",
      "AUC-PRC (macro): 0.5536\n",
      "AUC-ROC (macro): 0.9364\n",
      "Validation Accuracy: 47.50%\n",
      "Saved best model for Fold 2 at epoch 13\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 14] Loss: 44.0945 | CE: 35.6211 | U: 8.4729 | Contrastive: 0.0010\n",
      "AUC-PRC (macro): 0.4746\n",
      "AUC-ROC (macro): 0.9201\n",
      "Validation Accuracy: 38.75%\n",
      "  Pseudo-labels used: 13.0 / 16\n",
      "[Epoch 15] Loss: 41.7534 | CE: 33.8096 | U: 7.9435 | Contrastive: 0.0007\n",
      "AUC-PRC (macro): 0.5762\n",
      "AUC-ROC (macro): 0.9544\n",
      "Validation Accuracy: 50.50%\n",
      "Saved best model for Fold 2 at epoch 15\n",
      "  Pseudo-labels used: 13.0 / 16\n",
      "[Epoch 16] Loss: 41.6053 | CE: 31.0932 | U: 10.5118 | Contrastive: 0.0006\n",
      "AUC-PRC (macro): 0.6069\n",
      "AUC-ROC (macro): 0.9568\n",
      "Validation Accuracy: 50.25%\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 17] Loss: 40.8663 | CE: 33.2138 | U: 7.6522 | Contrastive: 0.0006\n",
      "AUC-PRC (macro): 0.5264\n",
      "AUC-ROC (macro): 0.9341\n",
      "Validation Accuracy: 46.25%\n",
      "  Pseudo-labels used: 12.0 / 16\n",
      "[Epoch 18] Loss: 38.3795 | CE: 28.5990 | U: 9.7802 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6363\n",
      "AUC-ROC (macro): 0.9586\n",
      "Validation Accuracy: 53.25%\n",
      "Saved best model for Fold 2 at epoch 18\n",
      "  Pseudo-labels used: 14.0 / 16\n",
      "[Epoch 19] Loss: 33.3370 | CE: 26.2084 | U: 7.1284 | Contrastive: 0.0004\n",
      "AUC-PRC (macro): 0.6079\n",
      "AUC-ROC (macro): 0.9489\n",
      "Validation Accuracy: 48.75%\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 20] Loss: 31.6090 | CE: 22.8657 | U: 8.7432 | Contrastive: 0.0004\n",
      "AUC-PRC (macro): 0.7043\n",
      "AUC-ROC (macro): 0.9635\n",
      "Validation Accuracy: 60.00%\n",
      "Saved best model for Fold 2 at epoch 20\n",
      "Best accuracy for fold 2: 60.00%\n",
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 1] Loss: 96.5360 | CE: 96.3922 | U: 0.0000 | Contrastive: 0.2876\n",
      "AUC-PRC (macro): 0.1749\n",
      "AUC-ROC (macro): 0.8209\n",
      "Validation Accuracy: 12.00%\n",
      "Saved best model for Fold 3 at epoch 1\n",
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 2] Loss: 83.5525 | CE: 83.5245 | U: 0.0185 | Contrastive: 0.0191\n",
      "AUC-PRC (macro): 0.2829\n",
      "AUC-ROC (macro): 0.8686\n",
      "Validation Accuracy: 17.00%\n",
      "Saved best model for Fold 3 at epoch 2\n",
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 3] Loss: 73.8096 | CE: 73.0257 | U: 0.7803 | Contrastive: 0.0072\n",
      "AUC-PRC (macro): 0.3118\n",
      "AUC-ROC (macro): 0.8859\n",
      "Validation Accuracy: 20.75%\n",
      "Saved best model for Fold 3 at epoch 3\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 4] Loss: 68.3760 | CE: 66.9902 | U: 1.3835 | Contrastive: 0.0046\n",
      "AUC-PRC (macro): 0.3495\n",
      "AUC-ROC (macro): 0.9298\n",
      "Validation Accuracy: 26.00%\n",
      "Saved best model for Fold 3 at epoch 4\n",
      "  Pseudo-labels used: 5.0 / 16\n",
      "[Epoch 5] Loss: 63.6408 | CE: 61.3858 | U: 2.2538 | Contrastive: 0.0023\n",
      "AUC-PRC (macro): 0.3841\n",
      "AUC-ROC (macro): 0.9263\n",
      "Validation Accuracy: 26.75%\n",
      "Saved best model for Fold 3 at epoch 5\n",
      "  Pseudo-labels used: 3.0 / 16\n",
      "[Epoch 6] Loss: 58.5255 | CE: 55.1975 | U: 3.3269 | Contrastive: 0.0021\n",
      "AUC-PRC (macro): 0.4197\n",
      "AUC-ROC (macro): 0.9337\n",
      "Validation Accuracy: 30.75%\n",
      "Saved best model for Fold 3 at epoch 6\n",
      "  Pseudo-labels used: 3.0 / 16\n",
      "[Epoch 7] Loss: 58.2593 | CE: 54.0211 | U: 4.2373 | Contrastive: 0.0018\n",
      "AUC-PRC (macro): 0.4264\n",
      "AUC-ROC (macro): 0.9281\n",
      "Validation Accuracy: 31.50%\n",
      "Saved best model for Fold 3 at epoch 7\n",
      "  Pseudo-labels used: 4.0 / 16\n",
      "[Epoch 8] Loss: 52.2870 | CE: 47.9609 | U: 4.3253 | Contrastive: 0.0016\n",
      "AUC-PRC (macro): 0.4659\n",
      "AUC-ROC (macro): 0.9384\n",
      "Validation Accuracy: 33.75%\n",
      "Saved best model for Fold 3 at epoch 8\n",
      "  Pseudo-labels used: 5.0 / 16\n",
      "[Epoch 9] Loss: 50.9809 | CE: 45.1872 | U: 5.7930 | Contrastive: 0.0013\n",
      "AUC-PRC (macro): 0.4872\n",
      "AUC-ROC (macro): 0.9409\n",
      "Validation Accuracy: 42.25%\n",
      "Saved best model for Fold 3 at epoch 9\n",
      "  Pseudo-labels used: 6.0 / 16\n",
      "[Epoch 10] Loss: 46.4128 | CE: 40.9633 | U: 5.4489 | Contrastive: 0.0011\n",
      "AUC-PRC (macro): 0.5516\n",
      "AUC-ROC (macro): 0.9558\n",
      "Validation Accuracy: 45.50%\n",
      "Saved best model for Fold 3 at epoch 10\n",
      "  Pseudo-labels used: 9.0 / 16\n",
      "[Epoch 11] Loss: 43.1871 | CE: 37.2429 | U: 5.9437 | Contrastive: 0.0010\n",
      "AUC-PRC (macro): 0.5481\n",
      "AUC-ROC (macro): 0.9568\n",
      "Validation Accuracy: 45.00%\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 12] Loss: 43.0108 | CE: 35.5513 | U: 7.4592 | Contrastive: 0.0008\n",
      "AUC-PRC (macro): 0.5513\n",
      "AUC-ROC (macro): 0.9479\n",
      "Validation Accuracy: 46.00%\n",
      "Saved best model for Fold 3 at epoch 12\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 13] Loss: 41.3131 | CE: 33.0366 | U: 8.2762 | Contrastive: 0.0006\n",
      "AUC-PRC (macro): 0.5818\n",
      "AUC-ROC (macro): 0.9601\n",
      "Validation Accuracy: 45.00%\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 14] Loss: 38.2512 | CE: 30.2309 | U: 8.0199 | Contrastive: 0.0007\n",
      "AUC-PRC (macro): 0.6051\n",
      "AUC-ROC (macro): 0.9579\n",
      "Validation Accuracy: 51.00%\n",
      "Saved best model for Fold 3 at epoch 14\n",
      "  Pseudo-labels used: 9.0 / 16\n",
      "[Epoch 15] Loss: 37.3094 | CE: 29.6596 | U: 7.6495 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6242\n",
      "AUC-ROC (macro): 0.9636\n",
      "Validation Accuracy: 52.00%\n",
      "Saved best model for Fold 3 at epoch 15\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 16] Loss: 36.1380 | CE: 27.1653 | U: 8.9724 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.5994\n",
      "AUC-ROC (macro): 0.9521\n",
      "Validation Accuracy: 48.50%\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 17] Loss: 39.2868 | CE: 29.7651 | U: 9.5215 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6420\n",
      "AUC-ROC (macro): 0.9650\n",
      "Validation Accuracy: 55.00%\n",
      "Saved best model for Fold 3 at epoch 17\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 18] Loss: 32.4294 | CE: 23.5066 | U: 8.9225 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6086\n",
      "AUC-ROC (macro): 0.9579\n",
      "Validation Accuracy: 51.75%\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 19] Loss: 34.2587 | CE: 24.2587 | U: 9.9997 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6241\n",
      "AUC-ROC (macro): 0.9586\n",
      "Validation Accuracy: 51.75%\n",
      "  Pseudo-labels used: 14.0 / 16\n",
      "[Epoch 20] Loss: 32.4222 | CE: 23.9834 | U: 8.4386 | Contrastive: 0.0003\n",
      "AUC-PRC (macro): 0.5945\n",
      "AUC-ROC (macro): 0.9574\n",
      "Validation Accuracy: 47.75%\n",
      "Best accuracy for fold 3: 55.00%\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 1] Loss: 96.9830 | CE: 96.7901 | U: 0.0594 | Contrastive: 0.2672\n",
      "AUC-PRC (macro): 0.1618\n",
      "AUC-ROC (macro): 0.7777\n",
      "Validation Accuracy: 6.50%\n",
      "Saved best model for Fold 4 at epoch 1\n",
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 2] Loss: 84.8571 | CE: 84.6458 | U: 0.2013 | Contrastive: 0.0201\n",
      "AUC-PRC (macro): 0.2328\n",
      "AUC-ROC (macro): 0.8573\n",
      "Validation Accuracy: 15.00%\n",
      "Saved best model for Fold 4 at epoch 2\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 3] Loss: 74.5981 | CE: 73.7932 | U: 0.8020 | Contrastive: 0.0059\n",
      "AUC-PRC (macro): 0.2750\n",
      "AUC-ROC (macro): 0.8801\n",
      "Validation Accuracy: 18.50%\n",
      "Saved best model for Fold 4 at epoch 3\n",
      "  Pseudo-labels used: 2.0 / 16\n",
      "[Epoch 4] Loss: 70.1940 | CE: 69.3274 | U: 0.8645 | Contrastive: 0.0040\n",
      "AUC-PRC (macro): 0.3107\n",
      "AUC-ROC (macro): 0.8907\n",
      "Validation Accuracy: 22.50%\n",
      "Saved best model for Fold 4 at epoch 4\n",
      "  Pseudo-labels used: 4.0 / 16\n",
      "[Epoch 5] Loss: 66.9873 | CE: 64.9641 | U: 2.0215 | Contrastive: 0.0035\n",
      "AUC-PRC (macro): 0.3687\n",
      "AUC-ROC (macro): 0.9130\n",
      "Validation Accuracy: 28.25%\n",
      "Saved best model for Fold 4 at epoch 5\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 6] Loss: 67.2454 | CE: 64.5237 | U: 2.7203 | Contrastive: 0.0030\n",
      "AUC-PRC (macro): 0.3536\n",
      "AUC-ROC (macro): 0.9003\n",
      "Validation Accuracy: 24.75%\n",
      "  Pseudo-labels used: 6.0 / 16\n",
      "[Epoch 7] Loss: 59.4501 | CE: 57.1331 | U: 2.3160 | Contrastive: 0.0022\n",
      "AUC-PRC (macro): 0.4773\n",
      "AUC-ROC (macro): 0.9406\n",
      "Validation Accuracy: 37.00%\n",
      "Saved best model for Fold 4 at epoch 7\n",
      "  Pseudo-labels used: 4.0 / 16\n",
      "[Epoch 8] Loss: 60.2068 | CE: 55.7841 | U: 4.4219 | Contrastive: 0.0016\n",
      "AUC-PRC (macro): 0.4530\n",
      "AUC-ROC (macro): 0.9351\n",
      "Validation Accuracy: 36.75%\n",
      "  Pseudo-labels used: 5.0 / 16\n",
      "[Epoch 9] Loss: 55.0131 | CE: 52.3427 | U: 2.6698 | Contrastive: 0.0014\n",
      "AUC-PRC (macro): 0.4981\n",
      "AUC-ROC (macro): 0.9499\n",
      "Validation Accuracy: 42.50%\n",
      "Saved best model for Fold 4 at epoch 9\n",
      "  Pseudo-labels used: 6.0 / 16\n",
      "[Epoch 10] Loss: 49.4927 | CE: 45.3491 | U: 4.1430 | Contrastive: 0.0011\n",
      "AUC-PRC (macro): 0.5277\n",
      "AUC-ROC (macro): 0.9465\n",
      "Validation Accuracy: 42.75%\n",
      "Saved best model for Fold 4 at epoch 10\n",
      "  Pseudo-labels used: 5.0 / 16\n",
      "[Epoch 11] Loss: 48.0652 | CE: 44.0497 | U: 4.0152 | Contrastive: 0.0008\n",
      "AUC-PRC (macro): 0.5450\n",
      "AUC-ROC (macro): 0.9519\n",
      "Validation Accuracy: 48.50%\n",
      "Saved best model for Fold 4 at epoch 11\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 12] Loss: 46.7961 | CE: 41.7824 | U: 5.0131 | Contrastive: 0.0010\n",
      "AUC-PRC (macro): 0.5581\n",
      "AUC-ROC (macro): 0.9551\n",
      "Validation Accuracy: 44.00%\n",
      "  Pseudo-labels used: 6.0 / 16\n",
      "[Epoch 13] Loss: 41.2667 | CE: 35.3379 | U: 5.9283 | Contrastive: 0.0008\n",
      "AUC-PRC (macro): 0.5644\n",
      "AUC-ROC (macro): 0.9549\n",
      "Validation Accuracy: 47.25%\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 14] Loss: 43.6739 | CE: 37.2942 | U: 6.3793 | Contrastive: 0.0007\n",
      "AUC-PRC (macro): 0.5991\n",
      "AUC-ROC (macro): 0.9572\n",
      "Validation Accuracy: 49.75%\n",
      "Saved best model for Fold 4 at epoch 14\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 15] Loss: 42.9603 | CE: 35.3688 | U: 7.5912 | Contrastive: 0.0006\n",
      "AUC-PRC (macro): 0.6044\n",
      "AUC-ROC (macro): 0.9616\n",
      "Validation Accuracy: 52.25%\n",
      "Saved best model for Fold 4 at epoch 15\n",
      "  Pseudo-labels used: 9.0 / 16\n",
      "[Epoch 16] Loss: 39.9158 | CE: 32.1535 | U: 7.7621 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6298\n",
      "AUC-ROC (macro): 0.9598\n",
      "Validation Accuracy: 51.25%\n",
      "  Pseudo-labels used: 8.0 / 16\n",
      "[Epoch 17] Loss: 36.8727 | CE: 28.9472 | U: 7.9252 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6535\n",
      "AUC-ROC (macro): 0.9609\n",
      "Validation Accuracy: 54.75%\n",
      "Saved best model for Fold 4 at epoch 17\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 18] Loss: 36.0358 | CE: 28.0151 | U: 8.0205 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.6218\n",
      "AUC-ROC (macro): 0.9534\n",
      "Validation Accuracy: 54.00%\n",
      "  Pseudo-labels used: 9.0 / 16\n",
      "[Epoch 19] Loss: 34.3645 | CE: 25.6249 | U: 8.7394 | Contrastive: 0.0004\n",
      "AUC-PRC (macro): 0.6512\n",
      "AUC-ROC (macro): 0.9526\n",
      "Validation Accuracy: 52.50%\n",
      "  Pseudo-labels used: 13.0 / 16\n",
      "[Epoch 20] Loss: 33.1396 | CE: 24.8436 | U: 8.2958 | Contrastive: 0.0004\n",
      "AUC-PRC (macro): 0.6533\n",
      "AUC-ROC (macro): 0.9639\n",
      "Validation Accuracy: 55.50%\n",
      "Saved best model for Fold 4 at epoch 20\n",
      "Best accuracy for fold 4: 55.50%\n",
      "\n",
      "=== Fold 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudo-labels used: 0.0 / 16\n",
      "[Epoch 1] Loss: 99.1575 | CE: 98.5353 | U: 0.4968 | Contrastive: 0.2507\n",
      "AUC-PRC (macro): 0.1562\n",
      "AUC-ROC (macro): 0.7708\n",
      "Validation Accuracy: 9.50%\n",
      "Saved best model for Fold 5 at epoch 1\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 2] Loss: 84.6941 | CE: 84.5742 | U: 0.1112 | Contrastive: 0.0173\n",
      "AUC-PRC (macro): 0.2218\n",
      "AUC-ROC (macro): 0.8183\n",
      "Validation Accuracy: 13.75%\n",
      "Saved best model for Fold 5 at epoch 2\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 3] Loss: 75.2123 | CE: 74.9844 | U: 0.2256 | Contrastive: 0.0045\n",
      "AUC-PRC (macro): 0.2010\n",
      "AUC-ROC (macro): 0.8169\n",
      "Validation Accuracy: 16.75%\n",
      "Saved best model for Fold 5 at epoch 3\n",
      "  Pseudo-labels used: 1.0 / 16\n",
      "[Epoch 4] Loss: 73.8309 | CE: 72.5615 | U: 1.2681 | Contrastive: 0.0028\n",
      "AUC-PRC (macro): 0.3109\n",
      "AUC-ROC (macro): 0.8875\n",
      "Validation Accuracy: 21.00%\n",
      "Saved best model for Fold 5 at epoch 4\n",
      "  Pseudo-labels used: 3.0 / 16\n",
      "[Epoch 5] Loss: 65.3597 | CE: 62.9537 | U: 2.4046 | Contrastive: 0.0028\n",
      "AUC-PRC (macro): 0.3704\n",
      "AUC-ROC (macro): 0.9063\n",
      "Validation Accuracy: 28.75%\n",
      "Saved best model for Fold 5 at epoch 5\n",
      "  Pseudo-labels used: 4.0 / 16\n",
      "[Epoch 6] Loss: 59.3130 | CE: 57.0646 | U: 2.2476 | Contrastive: 0.0017\n",
      "AUC-PRC (macro): 0.3660\n",
      "AUC-ROC (macro): 0.9014\n",
      "Validation Accuracy: 30.75%\n",
      "Saved best model for Fold 5 at epoch 6\n",
      "  Pseudo-labels used: 4.0 / 16\n",
      "[Epoch 7] Loss: 59.1184 | CE: 55.0773 | U: 4.0405 | Contrastive: 0.0013\n",
      "AUC-PRC (macro): 0.4233\n",
      "AUC-ROC (macro): 0.9098\n",
      "Validation Accuracy: 30.00%\n",
      "  Pseudo-labels used: 5.0 / 16\n",
      "[Epoch 8] Loss: 54.5005 | CE: 50.7955 | U: 3.7043 | Contrastive: 0.0013\n",
      "AUC-PRC (macro): 0.4352\n",
      "AUC-ROC (macro): 0.9211\n",
      "Validation Accuracy: 35.25%\n",
      "Saved best model for Fold 5 at epoch 8\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 9] Loss: 51.1482 | CE: 44.7692 | U: 6.3784 | Contrastive: 0.0012\n",
      "AUC-PRC (macro): 0.4402\n",
      "AUC-ROC (macro): 0.9186\n",
      "Validation Accuracy: 33.75%\n",
      "  Pseudo-labels used: 5.0 / 16\n",
      "[Epoch 10] Loss: 50.1000 | CE: 44.6273 | U: 5.4722 | Contrastive: 0.0009\n",
      "AUC-PRC (macro): 0.4451\n",
      "AUC-ROC (macro): 0.9138\n",
      "Validation Accuracy: 36.25%\n",
      "Saved best model for Fold 5 at epoch 10\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 11] Loss: 47.7763 | CE: 40.9776 | U: 6.7982 | Contrastive: 0.0009\n",
      "AUC-PRC (macro): 0.4525\n",
      "AUC-ROC (macro): 0.9303\n",
      "Validation Accuracy: 36.50%\n",
      "Saved best model for Fold 5 at epoch 11\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 12] Loss: 47.2928 | CE: 39.2518 | U: 8.0407 | Contrastive: 0.0007\n",
      "AUC-PRC (macro): 0.4122\n",
      "AUC-ROC (macro): 0.9182\n",
      "Validation Accuracy: 29.75%\n",
      "  Pseudo-labels used: 13.0 / 16\n",
      "[Epoch 13] Loss: 41.1758 | CE: 34.9156 | U: 6.2599 | Contrastive: 0.0006\n",
      "AUC-PRC (macro): 0.5342\n",
      "AUC-ROC (macro): 0.9419\n",
      "Validation Accuracy: 47.50%\n",
      "Saved best model for Fold 5 at epoch 13\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 14] Loss: 43.1020 | CE: 35.4449 | U: 7.6568 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.5004\n",
      "AUC-ROC (macro): 0.9271\n",
      "Validation Accuracy: 40.25%\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 15] Loss: 37.8194 | CE: 30.2733 | U: 7.5459 | Contrastive: 0.0005\n",
      "AUC-PRC (macro): 0.4917\n",
      "AUC-ROC (macro): 0.9352\n",
      "Validation Accuracy: 43.25%\n",
      "  Pseudo-labels used: 7.0 / 16\n",
      "[Epoch 16] Loss: 36.6531 | CE: 28.6424 | U: 8.0104 | Contrastive: 0.0004\n",
      "AUC-PRC (macro): 0.5627\n",
      "AUC-ROC (macro): 0.9482\n",
      "Validation Accuracy: 48.25%\n",
      "Saved best model for Fold 5 at epoch 16\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 17] Loss: 35.0529 | CE: 26.2945 | U: 8.7583 | Contrastive: 0.0003\n",
      "AUC-PRC (macro): 0.5104\n",
      "AUC-ROC (macro): 0.9315\n",
      "Validation Accuracy: 44.00%\n",
      "  Pseudo-labels used: 11.0 / 16\n",
      "[Epoch 18] Loss: 37.2287 | CE: 28.1551 | U: 9.0735 | Contrastive: 0.0003\n",
      "AUC-PRC (macro): 0.5299\n",
      "AUC-ROC (macro): 0.9406\n",
      "Validation Accuracy: 44.25%\n",
      "  Pseudo-labels used: 10.0 / 16\n",
      "[Epoch 19] Loss: 32.2495 | CE: 23.5715 | U: 8.6779 | Contrastive: 0.0003\n",
      "AUC-PRC (macro): 0.5504\n",
      "AUC-ROC (macro): 0.9390\n",
      "Validation Accuracy: 48.50%\n",
      "Saved best model for Fold 5 at epoch 19\n",
      "  Pseudo-labels used: 13.0 / 16\n",
      "[Epoch 20] Loss: 29.0989 | CE: 19.7825 | U: 9.3163 | Contrastive: 0.0003\n",
      "AUC-PRC (macro): 0.5691\n",
      "AUC-ROC (macro): 0.9393\n",
      "Validation Accuracy: 49.50%\n",
      "Saved best model for Fold 5 at epoch 20\n",
      "Best accuracy for fold 5: 49.50%\n",
      "\n",
      "=== 5-Fold Summary ===\n",
      "\n",
      "Fold 1:\n",
      "  accuracy: 60.0000\n",
      "  precision: 0.6417\n",
      "  recall: 0.6000\n",
      "  f1: 0.5892\n",
      "  auc_prc: 0.7043\n",
      "  auc_roc: 0.9635\n",
      "\n",
      "Fold 2:\n",
      "  accuracy: 55.0000\n",
      "  precision: 0.5889\n",
      "  recall: 0.5500\n",
      "  f1: 0.5278\n",
      "  auc_prc: 0.6420\n",
      "  auc_roc: 0.9650\n",
      "\n",
      "Fold 3:\n",
      "  accuracy: 55.5000\n",
      "  precision: 0.6016\n",
      "  recall: 0.5550\n",
      "  f1: 0.5288\n",
      "  auc_prc: 0.6533\n",
      "  auc_roc: 0.9639\n",
      "\n",
      "Fold 4:\n",
      "  accuracy: 49.5000\n",
      "  precision: 0.5486\n",
      "  recall: 0.4950\n",
      "  f1: 0.4778\n",
      "  auc_prc: 0.5691\n",
      "  auc_roc: 0.9393\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  accuracy: 55.0000\n",
      "  precision: 0.5952\n",
      "  recall: 0.5500\n",
      "  f1: 0.5309\n",
      "  auc_prc: 0.6422\n",
      "  auc_roc: 0.9579\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "labeled_fraction = 0.2\n",
    "split_dir = \"labeled-unlabeled\"\n",
    "\n",
    "fold_accuracies = []\n",
    "fold_metrics = []\n",
    "\n",
    "save_dir = \"models/ESC-50/EPASS\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for fold in range(2, 6):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Load data loaders from saved splits\n",
    "    labeled_loader, unlabeled_loader, val_loader = get_ssl_loaders(\n",
    "        meta_df=meta_df,\n",
    "        labeled_fraction=labeled_fraction,\n",
    "        fold=fold,\n",
    "        batch_size=batch_size,\n",
    "        split_dir=split_dir\n",
    "    )\n",
    "\n",
    "    # Reinitialize model and optimizer for each fold\n",
    "    encoder = ResNet1DAudioEncoder(embed_dim=256).to(device)\n",
    "    projectors = EPASSProjectors(embed_dim=256, proj_dim=128, num_proj=3).to(device)\n",
    "    classifier = nn.Linear(256, 50).to(device)\n",
    "\n",
    "    params = list(encoder.parameters()) + list(projectors.parameters()) + list(classifier.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "\n",
    "    best_metric = None\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_one_epoch(\n",
    "            encoder,\n",
    "            projectors,\n",
    "            classifier,\n",
    "            labeled_loader,\n",
    "            unlabeled_loader,\n",
    "            optimizer,\n",
    "            device,\n",
    "            epoch,\n",
    "            confidence_thresh=0.5\n",
    "        )\n",
    "        metrics = evaluate(\n",
    "            encoder,\n",
    "            classifier,\n",
    "            val_loader,\n",
    "            device,\n",
    "            num_classes=50,\n",
    "            plot_loss_curves=False\n",
    "        )\n",
    "\n",
    "        acc = metrics[\"accuracy\"]\n",
    "        print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "        if metrics[\"accuracy\"] > best_acc:\n",
    "            best_acc = metrics[\"accuracy\"]\n",
    "            best_metrics = metrics\n",
    "            torch.save({\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'projectors_state_dict': projectors.state_dict(),\n",
    "                'classifier_state_dict': classifier.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'fold': fold,\n",
    "                'epoch': epoch,\n",
    "                'metrics': best_metrics\n",
    "            }, os.path.join(save_dir, f\"best_model_fold{fold}.pt\"))\n",
    "            print(f\"Saved best model for Fold {fold} at epoch {epoch}\")\n",
    "\n",
    "    fold_accuracies.append(best_acc)\n",
    "    fold_metrics.append(best_metrics)\n",
    "    print(f\"Best accuracy for fold {fold}: {best_acc:.2f}%\")\n",
    "\n",
    "# Summary of all stats\n",
    "print(\"\\n=== 5-Fold Summary ===\")\n",
    "avg_metrics = {}\n",
    "\n",
    "for i, m in enumerate(fold_metrics, 1):\n",
    "    print(f\"\\nFold {i}:\")\n",
    "    for k, v in m.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "        avg_metrics[k] = avg_metrics.get(k, 0.0) + (v if v is not None else 0.0)\n",
    "\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "for k, total in avg_metrics.items():\n",
    "    avg_val = total / len(fold_metrics)\n",
    "    print(f\"  {k}: {avg_val:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad4865-da6c-4f81-81d4-6f3e438d0b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
