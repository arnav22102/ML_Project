{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c486cb5c-61bf-47b1-9b8b-f2dc3e25f463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-100032-A-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-100038-A-14.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-100210-A-36.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "      <td>ESC-50-master/audio/1-100210-B-36.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "      <td>ESC-50-master/audio/1-101296-A-19.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take  \\\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A   \n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A   \n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A   \n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B   \n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A   \n",
       "\n",
       "                                filepath  \n",
       "0   ESC-50-master/audio/1-100032-A-0.wav  \n",
       "1  ESC-50-master/audio/1-100038-A-14.wav  \n",
       "2  ESC-50-master/audio/1-100210-A-36.wav  \n",
       "3  ESC-50-master/audio/1-100210-B-36.wav  \n",
       "4  ESC-50-master/audio/1-101296-A-19.wav  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load CSV metadata\n",
    "meta_df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "# Add full path to audio files\n",
    "meta_df['filepath'] = meta_df['filename'].apply(lambda x: os.path.join('ESC-50-master/audio/', x))\n",
    "\n",
    "# Display sample\n",
    "meta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd13a48-4366-4b17-9bdb-81791a577e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, Gain\n",
    "\n",
    "class ESC50Dataset(Dataset):\n",
    "    def __init__(self, df, sample_rate=44100, duration=5.0, augment_type='none', n_mels=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sr = sample_rate\n",
    "        self.length = int(sample_rate * duration)\n",
    "        self.augment_type = augment_type\n",
    "        self.n_mels = n_mels\n",
    "\n",
    "        self.weak_transform = Compose([\n",
    "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        ])\n",
    "        self.strong_transform = Compose([\n",
    "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.02, p=0.5),\n",
    "            PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "            TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            Gain(min_gain_db=-6, max_gain_db=6, p=0.5)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = row['filepath']\n",
    "        label = row['target'] if 'target' in row else -1\n",
    "\n",
    "        y, _ = librosa.load(path, sr=self.sr)\n",
    "        if len(y) < self.length:\n",
    "            y = np.pad(y, (0, self.length - len(y)))\n",
    "        else:\n",
    "            y = y[:self.length]\n",
    "\n",
    "        if self.augment_type == 'weak':\n",
    "            y = self.weak_transform(samples=y, sample_rate=self.sr)\n",
    "        elif self.augment_type == 'strong':\n",
    "            y = self.strong_transform(samples=y, sample_rate=self.sr)\n",
    "\n",
    "        # Convert to Mel spectrogram\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=self.sr, n_mels=self.n_mels)\n",
    "        mel_db = librosa.power_to_db(mel + 1e-6, ref=np.max)\n",
    "        mel_db = np.clip(mel_db, a_min=-80, a_max=0)  # Avoid crazy ranges\n",
    "\n",
    "\n",
    "        # Normalize and convert to torch tensor [1, H, W]\n",
    "        mel_tensor = torch.tensor(mel_db, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return mel_tensor, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80832c59-5a08-4aa7-aefa-6749baf4e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labeled_unlabeled_and_save(df, labeled_fraction=0.1, save_dir=\"labeled-unlabeled\"):\n",
    "    import os\n",
    "    os.makedirs(f'{save_dir}/{labeled_fraction}', exist_ok=True)\n",
    "\n",
    "    labeled_df_list = []\n",
    "    unlabeled_df_list = []\n",
    "\n",
    "    for label in sorted(df['target'].unique()):\n",
    "        class_df = df[df['target'] == label]\n",
    "        n_total = len(class_df)\n",
    "        n_labeled = max(1, int(n_total * labeled_fraction))\n",
    "\n",
    "        labeled = class_df.sample(n=n_labeled, random_state=42)\n",
    "        unlabeled = class_df.drop(labeled.index)\n",
    "\n",
    "        labeled_df_list.append(labeled)\n",
    "        unlabeled_df_list.append(unlabeled)\n",
    "\n",
    "    labeled_df = pd.concat(labeled_df_list).reset_index(drop=True)\n",
    "    unlabeled_df = pd.concat(unlabeled_df_list).reset_index(drop=True)\n",
    "\n",
    "    # Drop label/category from the unlabeled set\n",
    "    unlabeled_df = unlabeled_df.drop(columns=[\"target\", \"category\"])\n",
    "\n",
    "    labeled_df.head()\n",
    "    unlabeled_df.head()\n",
    "    \n",
    "    # Save both\n",
    "    labeled_df.to_csv(f\"{save_dir}/{labeled_fraction}/labeled.csv\", index=False)      # with labels\n",
    "    unlabeled_df.to_csv(f\"{save_dir}/{labeled_fraction}/unlabeled.csv\", index=False)  # without labels\n",
    "\n",
    "    print(f\"Saved labeled.csv (with labels) and unlabeled.csv (no labels) to '{save_dir}/{labeled_fraction}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b63ed7d-9c47-4d54-943d-60dfe72fc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_ssl_loaders(meta_df,labeled_fraction=0.1, fold=1, batch_size=16, split_dir=\"labeled-unlabeled\"):\n",
    "    # Load pre-saved labeled and unlabeled CSVs for this fold\n",
    "    labeled_df = pd.read_csv(f\"{split_dir}/{labeled_fraction}/labeled.csv\")\n",
    "    unlabeled_df = pd.read_csv(f\"{split_dir}/{labeled_fraction}/unlabeled.csv\")\n",
    "\n",
    "    # Get validation set from meta_df\n",
    "    val_df = meta_df[meta_df['fold'] == fold]\n",
    "\n",
    "    # Create datasets\n",
    "    labeled_dataset = ESC50Dataset(labeled_df, augment_type='weak')\n",
    "    unlabeled_dataset = DualViewESC50Dataset(unlabeled_df)\n",
    "    val_dataset = ESC50Dataset(val_df, augment_type='none')\n",
    "\n",
    "    # Create loaders\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    return labeled_loader, unlabeled_loader, val_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cff4a99-f44a-4161-a45a-5ea98eed4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualViewESC50Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.weak_dataset = ESC50Dataset(df, augment_type='weak')\n",
    "        self.strong_dataset = ESC50Dataset(df, augment_type='strong')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.weak_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        weak_x, _ = self.weak_dataset[idx]\n",
    "        strong_x, _ = self.strong_dataset[idx]\n",
    "        return weak_x, strong_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d8091d-f6b1-47a6-9122-7f0d08a5d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class ESC50CNN(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.base = models.resnet18(pretrained=True)\n",
    "        self.base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.base.fc = nn.Linear(self.base.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base(x)\n",
    "\n",
    "def get_perturbation(model, labeled_loader, loss_fn, rho=0.1):\n",
    "    model.train()\n",
    "    for x, y in labeled_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x.requires_grad = True\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        grad = []\n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                grad.append(param.grad.view(-1))\n",
    "        grad_vector = torch.cat(grad)\n",
    "        norm = torch.norm(grad_vector, p=2)\n",
    "        eps = rho * grad_vector / (norm + 1e-12)\n",
    "\n",
    "        # Apply perturbation\n",
    "        i = 0\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                numel = param.numel()\n",
    "                param.data.add_(eps[i:i+numel].view_as(param))\n",
    "                i += numel\n",
    "        break  # Use only 1 batch\n",
    "    return model\n",
    "\n",
    "def cross_sharpness_loss(model_orig, model_perturbed, unlabeled_loader):\n",
    "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "    model_orig.eval()\n",
    "    model_perturbed.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for weak_x, _ in unlabeled_loader:\n",
    "            weak_x = weak_x.to(device)\n",
    "\n",
    "            # Safe softmax/log_softmax with clamping\n",
    "            out_orig = torch.clamp(torch.softmax(model_orig(weak_x), dim=1), min=1e-7)\n",
    "            out_pert = torch.log_softmax(model_perturbed(weak_x), dim=1)\n",
    "\n",
    "            loss = criterion(out_pert, out_orig)\n",
    "            break\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ab3423-2eed-4888-b9d5-9248fb7a509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_flatmatch_one_epoch(model, labeled_loader, unlabeled_loader, optimizer, device, epoch, rho=0.1):\n",
    "    model.train()\n",
    "    total_loss, total_labeled_loss, total_cs_loss = 0.0, 0.0, 0.0\n",
    "\n",
    "    unlabeled_iter = iter(unlabeled_loader)\n",
    "\n",
    "    for x_l, y_l in labeled_loader:\n",
    "        try:\n",
    "            xw, xs = next(unlabeled_iter)\n",
    "        except StopIteration:\n",
    "            unlabeled_iter = iter(unlabeled_loader)\n",
    "            xw, xs = next(unlabeled_iter)\n",
    "\n",
    "        x_l, y_l = x_l.to(device), y_l.to(device)\n",
    "        xw = xw.to(device)  # Only weak used in flatmatch (strong is ignored)\n",
    "\n",
    "        # Supervised loss\n",
    "        logits_l = model(x_l)\n",
    "        ce_loss = F.cross_entropy(logits_l, y_l)\n",
    "\n",
    "        # Perturb model on labeled batch\n",
    "        model_perturbed = get_perturbation(copy.deepcopy(model), [(x_l, y_l)], F.cross_entropy, rho=rho)\n",
    "\n",
    "        # Cross-sharpness KL divergence\n",
    "        with torch.no_grad():\n",
    "            p_orig = torch.clamp(F.softmax(model(xw), dim=1), min=1e-7)\n",
    "        p_pert = F.log_softmax(model_perturbed(xw), dim=1)\n",
    "        cs_loss = F.kl_div(p_pert, p_orig, reduction=\"batchmean\")\n",
    "\n",
    "        loss = ce_loss + cs_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_labeled_loss += ce_loss.item()\n",
    "        total_cs_loss += cs_loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Loss: {total_loss:.4f} | CE: {total_labeled_loss:.4f} | CrossSharp: {total_cs_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98e793a-4a2d-45a7-87ce-333dab2831f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(encoder, classifier, val_loader, device, num_classes=50, plot_loss_curves=False, train_losses=None, val_losses=None):\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = classifier(encoder(x))\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # print(f\"\\nValidation Accuracy: {acc:.2f}%\")\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    # Core metrics\n",
    "    precision = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # AUC-PRC\n",
    "    try:\n",
    "        auc_prc = average_precision_score(\n",
    "            y_true=np.eye(num_classes)[all_labels],\n",
    "            y_score=all_probs,\n",
    "            average=\"macro\"\n",
    "        )\n",
    "        print(f\"AUC-PRC (macro): {auc_prc:.4f}\")\n",
    "    except Exception as e:\n",
    "        auc_prc = None\n",
    "        print(f\"AUC-PRC: Not computable — {str(e)}\")\n",
    "\n",
    "    # AUC-ROC\n",
    "    try:\n",
    "        auc_roc = roc_auc_score(\n",
    "            y_true=np.eye(num_classes)[all_labels],\n",
    "            y_score=all_probs,\n",
    "            average=\"macro\",\n",
    "            multi_class='ovr'\n",
    "        )\n",
    "        print(f\"AUC-ROC (macro): {auc_roc:.4f}\")\n",
    "    except Exception as e:\n",
    "        auc_roc = None\n",
    "        print(f\"AUC-ROC: Not computable — {str(e)}\")\n",
    "\n",
    "    # Optional: Plot Loss Curves\n",
    "    if plot_loss_curves and train_losses and val_losses:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Train vs Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Return all stats\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"auc_prc\": auc_prc,\n",
    "        \"auc_roc\": auc_roc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad29110-42e9-4048-b797-659d0ab4560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved model for Fold 1. Loading checkpoint...\n",
      "[Epoch 20] Loss: 4.4667 | CE: 3.9756 | CrossSharp: 0.4911\n",
      "AUC-PRC (macro): 0.6752\n",
      "AUC-ROC (macro): 0.9579\n",
      "Validation Accuracy: 59.25%\n",
      "[Epoch 21] Loss: 5.0378 | CE: 4.5590 | CrossSharp: 0.4788\n",
      "AUC-PRC (macro): 0.6588\n",
      "AUC-ROC (macro): 0.9491\n",
      "Validation Accuracy: 54.50%\n",
      "[Epoch 22] Loss: 7.9515 | CE: 7.4259 | CrossSharp: 0.5257\n",
      "AUC-PRC (macro): 0.6674\n",
      "AUC-ROC (macro): 0.9565\n",
      "Validation Accuracy: 60.25%\n",
      "[Epoch 23] Loss: 5.1372 | CE: 4.7690 | CrossSharp: 0.3682\n",
      "AUC-PRC (macro): 0.6274\n",
      "AUC-ROC (macro): 0.9517\n",
      "Validation Accuracy: 54.75%\n",
      "[Epoch 24] Loss: 4.6626 | CE: 4.3759 | CrossSharp: 0.2867\n",
      "AUC-PRC (macro): 0.6868\n",
      "AUC-ROC (macro): 0.9626\n",
      "Validation Accuracy: 58.00%\n",
      "[Epoch 25] Loss: 4.7298 | CE: 4.2589 | CrossSharp: 0.4709\n",
      "AUC-PRC (macro): 0.6725\n",
      "AUC-ROC (macro): 0.9624\n",
      "Validation Accuracy: 58.50%\n",
      "[Epoch 26] Loss: 2.9814 | CE: 2.6387 | CrossSharp: 0.3427\n",
      "AUC-PRC (macro): 0.6866\n",
      "AUC-ROC (macro): 0.9687\n",
      "Validation Accuracy: 57.00%\n",
      "[Epoch 27] Loss: 2.8497 | CE: 2.4110 | CrossSharp: 0.4387\n",
      "AUC-PRC (macro): 0.6734\n",
      "AUC-ROC (macro): 0.9656\n",
      "Validation Accuracy: 57.00%\n",
      "[Epoch 28] Loss: 3.0155 | CE: 2.5999 | CrossSharp: 0.4157\n",
      "AUC-PRC (macro): 0.6906\n",
      "AUC-ROC (macro): 0.9657\n",
      "Validation Accuracy: 60.50%\n",
      "Saved best model for Fold 1 at epoch 28\n",
      "[Epoch 29] Loss: 1.6663 | CE: 1.1039 | CrossSharp: 0.5624\n",
      "AUC-PRC (macro): 0.7028\n",
      "AUC-ROC (macro): 0.9696\n",
      "Validation Accuracy: 59.75%\n",
      "Best accuracy for Fold 1: 60.50%\n",
      "\n",
      "=== Fold 2 ===\n",
      "Found saved model for Fold 2. Loading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Loss: 5.4350 | CE: 4.8431 | CrossSharp: 0.5919\n",
      "AUC-PRC (macro): 0.7559\n",
      "AUC-ROC (macro): 0.9672\n",
      "Validation Accuracy: 64.00%\n",
      "[Epoch 22] Loss: 5.1483 | CE: 4.4742 | CrossSharp: 0.6741\n",
      "AUC-PRC (macro): 0.7588\n",
      "AUC-ROC (macro): 0.9727\n",
      "Validation Accuracy: 65.00%\n",
      "[Epoch 23] Loss: 4.7671 | CE: 4.3925 | CrossSharp: 0.3747\n",
      "AUC-PRC (macro): 0.7540\n",
      "AUC-ROC (macro): 0.9696\n",
      "Validation Accuracy: 66.25%\n",
      "Saved best model for Fold 2 at epoch 23\n",
      "[Epoch 24] Loss: 3.6879 | CE: 3.3208 | CrossSharp: 0.3671\n",
      "AUC-PRC (macro): 0.7722\n",
      "AUC-ROC (macro): 0.9754\n",
      "Validation Accuracy: 67.50%\n",
      "Saved best model for Fold 2 at epoch 24\n",
      "[Epoch 25] Loss: 2.5876 | CE: 2.1488 | CrossSharp: 0.4387\n",
      "AUC-PRC (macro): 0.7956\n",
      "AUC-ROC (macro): 0.9775\n",
      "Validation Accuracy: 70.00%\n",
      "Saved best model for Fold 2 at epoch 25\n",
      "[Epoch 26] Loss: 1.4980 | CE: 1.1899 | CrossSharp: 0.3081\n",
      "AUC-PRC (macro): 0.7782\n",
      "AUC-ROC (macro): 0.9748\n",
      "Validation Accuracy: 69.00%\n",
      "[Epoch 27] Loss: 1.9038 | CE: 1.4835 | CrossSharp: 0.4203\n",
      "AUC-PRC (macro): 0.7941\n",
      "AUC-ROC (macro): 0.9785\n",
      "Validation Accuracy: 68.50%\n",
      "[Epoch 28] Loss: 1.6617 | CE: 1.2684 | CrossSharp: 0.3933\n",
      "AUC-PRC (macro): 0.7933\n",
      "AUC-ROC (macro): 0.9805\n",
      "Validation Accuracy: 70.00%\n",
      "[Epoch 29] Loss: 1.8448 | CE: 1.4382 | CrossSharp: 0.4067\n",
      "AUC-PRC (macro): 0.7962\n",
      "AUC-ROC (macro): 0.9767\n",
      "Validation Accuracy: 68.00%\n",
      "[Epoch 30] Loss: 0.8737 | CE: 0.5685 | CrossSharp: 0.3052\n",
      "AUC-PRC (macro): 0.8161\n",
      "AUC-ROC (macro): 0.9808\n",
      "Validation Accuracy: 69.25%\n",
      "Best accuracy for Fold 2: 70.00%\n",
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved model for Fold 3. Loading checkpoint...\n",
      "[Epoch 18] Loss: 6.6607 | CE: 6.2889 | CrossSharp: 0.3717\n",
      "AUC-PRC (macro): 0.7521\n",
      "AUC-ROC (macro): 0.9732\n",
      "Validation Accuracy: 63.00%\n",
      "[Epoch 19] Loss: 4.8829 | CE: 4.4257 | CrossSharp: 0.4572\n",
      "AUC-PRC (macro): 0.8057\n",
      "AUC-ROC (macro): 0.9811\n",
      "Validation Accuracy: 71.00%\n",
      "Saved best model for Fold 3 at epoch 19\n",
      "[Epoch 20] Loss: 5.3251 | CE: 4.7786 | CrossSharp: 0.5465\n",
      "AUC-PRC (macro): 0.8291\n",
      "AUC-ROC (macro): 0.9882\n",
      "Validation Accuracy: 73.75%\n",
      "Saved best model for Fold 3 at epoch 20\n",
      "[Epoch 21] Loss: 4.0788 | CE: 3.5869 | CrossSharp: 0.4919\n",
      "AUC-PRC (macro): 0.8135\n",
      "AUC-ROC (macro): 0.9841\n",
      "Validation Accuracy: 69.75%\n",
      "[Epoch 22] Loss: 4.6072 | CE: 4.0782 | CrossSharp: 0.5290\n",
      "AUC-PRC (macro): 0.7874\n",
      "AUC-ROC (macro): 0.9784\n",
      "Validation Accuracy: 69.25%\n",
      "[Epoch 23] Loss: 6.7049 | CE: 6.2524 | CrossSharp: 0.4525\n",
      "AUC-PRC (macro): 0.7773\n",
      "AUC-ROC (macro): 0.9763\n",
      "Validation Accuracy: 69.50%\n",
      "[Epoch 24] Loss: 4.6092 | CE: 4.1673 | CrossSharp: 0.4419\n",
      "AUC-PRC (macro): 0.8009\n",
      "AUC-ROC (macro): 0.9739\n",
      "Validation Accuracy: 69.00%\n",
      "[Epoch 25] Loss: 5.0661 | CE: 4.4386 | CrossSharp: 0.6275\n",
      "AUC-PRC (macro): 0.7724\n",
      "AUC-ROC (macro): 0.9783\n",
      "Validation Accuracy: 68.75%\n",
      "[Epoch 26] Loss: 6.0463 | CE: 5.5296 | CrossSharp: 0.5168\n",
      "AUC-PRC (macro): 0.7891\n",
      "AUC-ROC (macro): 0.9775\n",
      "Validation Accuracy: 69.50%\n",
      "[Epoch 27] Loss: 3.5618 | CE: 3.0211 | CrossSharp: 0.5407\n",
      "AUC-PRC (macro): 0.8174\n",
      "AUC-ROC (macro): 0.9806\n",
      "Validation Accuracy: 69.00%\n",
      "Best accuracy for Fold 3: 73.75%\n",
      "\n",
      "=== Fold 4 ===\n",
      "Found saved model for Fold 4. Loading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Loss: 3.9905 | CE: 3.6162 | CrossSharp: 0.3743\n",
      "AUC-PRC (macro): 0.7930\n",
      "AUC-ROC (macro): 0.9727\n",
      "Validation Accuracy: 68.25%\n",
      "[Epoch 21] Loss: 4.0343 | CE: 3.4990 | CrossSharp: 0.5353\n",
      "AUC-PRC (macro): 0.7860\n",
      "AUC-ROC (macro): 0.9725\n",
      "Validation Accuracy: 68.50%\n",
      "[Epoch 22] Loss: 6.2828 | CE: 5.4211 | CrossSharp: 0.8617\n",
      "AUC-PRC (macro): 0.7125\n",
      "AUC-ROC (macro): 0.9592\n",
      "Validation Accuracy: 61.75%\n",
      "[Epoch 23] Loss: 8.0912 | CE: 7.5167 | CrossSharp: 0.5745\n",
      "AUC-PRC (macro): 0.7715\n",
      "AUC-ROC (macro): 0.9736\n",
      "Validation Accuracy: 67.25%\n",
      "[Epoch 24] Loss: 5.0631 | CE: 4.5213 | CrossSharp: 0.5418\n",
      "AUC-PRC (macro): 0.7854\n",
      "AUC-ROC (macro): 0.9789\n",
      "Validation Accuracy: 69.75%\n",
      "[Epoch 25] Loss: 3.1063 | CE: 2.6304 | CrossSharp: 0.4759\n",
      "AUC-PRC (macro): 0.7795\n",
      "AUC-ROC (macro): 0.9767\n",
      "Validation Accuracy: 65.50%\n",
      "[Epoch 26] Loss: 3.8216 | CE: 3.3493 | CrossSharp: 0.4723\n",
      "AUC-PRC (macro): 0.7468\n",
      "AUC-ROC (macro): 0.9672\n",
      "Validation Accuracy: 66.25%\n",
      "[Epoch 27] Loss: 4.5374 | CE: 4.0556 | CrossSharp: 0.4818\n",
      "AUC-PRC (macro): 0.7815\n",
      "AUC-ROC (macro): 0.9728\n",
      "Validation Accuracy: 69.00%\n",
      "[Epoch 28] Loss: 4.0337 | CE: 3.6078 | CrossSharp: 0.4259\n",
      "AUC-PRC (macro): 0.7710\n",
      "AUC-ROC (macro): 0.9744\n",
      "Validation Accuracy: 67.50%\n",
      "[Epoch 29] Loss: 2.5638 | CE: 1.9831 | CrossSharp: 0.5807\n",
      "AUC-PRC (macro): 0.7893\n",
      "AUC-ROC (macro): 0.9768\n",
      "Validation Accuracy: 69.00%\n",
      "Best accuracy for Fold 4: 70.50%\n",
      "\n",
      "=== Fold 5 ===\n",
      "Found saved model for Fold 5. Loading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Loss: 8.6932 | CE: 8.1874 | CrossSharp: 0.5058\n",
      "AUC-PRC (macro): 0.6079\n",
      "AUC-ROC (macro): 0.9463\n",
      "Validation Accuracy: 49.25%\n",
      "[Epoch 22] Loss: 7.4399 | CE: 6.9611 | CrossSharp: 0.4788\n",
      "AUC-PRC (macro): 0.6129\n",
      "AUC-ROC (macro): 0.9462\n",
      "Validation Accuracy: 52.50%\n",
      "[Epoch 23] Loss: 5.3901 | CE: 4.7309 | CrossSharp: 0.6593\n",
      "AUC-PRC (macro): 0.6780\n",
      "AUC-ROC (macro): 0.9627\n",
      "Validation Accuracy: 58.00%\n",
      "[Epoch 24] Loss: 7.0740 | CE: 6.5913 | CrossSharp: 0.4827\n",
      "AUC-PRC (macro): 0.6412\n",
      "AUC-ROC (macro): 0.9533\n",
      "Validation Accuracy: 55.00%\n",
      "[Epoch 25] Loss: 5.6567 | CE: 5.1186 | CrossSharp: 0.5381\n",
      "AUC-PRC (macro): 0.6682\n",
      "AUC-ROC (macro): 0.9504\n",
      "Validation Accuracy: 59.00%\n",
      "Saved best model for Fold 5 at epoch 25\n",
      "[Epoch 26] Loss: 6.0656 | CE: 5.5379 | CrossSharp: 0.5277\n",
      "AUC-PRC (macro): 0.6503\n",
      "AUC-ROC (macro): 0.9545\n",
      "Validation Accuracy: 56.25%\n",
      "[Epoch 27] Loss: 3.9672 | CE: 3.6098 | CrossSharp: 0.3574\n",
      "AUC-PRC (macro): 0.6847\n",
      "AUC-ROC (macro): 0.9599\n",
      "Validation Accuracy: 57.50%\n",
      "[Epoch 28] Loss: 2.6296 | CE: 2.2851 | CrossSharp: 0.3444\n",
      "AUC-PRC (macro): 0.6593\n",
      "AUC-ROC (macro): 0.9547\n",
      "Validation Accuracy: 58.75%\n",
      "[Epoch 29] Loss: 2.6504 | CE: 2.1608 | CrossSharp: 0.4896\n",
      "AUC-PRC (macro): 0.6919\n",
      "AUC-ROC (macro): 0.9588\n",
      "Validation Accuracy: 61.00%\n",
      "Saved best model for Fold 5 at epoch 29\n",
      "[Epoch 30] Loss: 1.9405 | CE: 1.5184 | CrossSharp: 0.4221\n",
      "AUC-PRC (macro): 0.6845\n",
      "AUC-ROC (macro): 0.9556\n",
      "Validation Accuracy: 59.00%\n",
      "Best accuracy for Fold 5: 61.00%\n",
      "\n",
      "=== 5-Fold Summary ===\n",
      "\n",
      "Fold 1:\n",
      "  accuracy: 60.5000\n",
      "  precision: 0.6752\n",
      "  recall: 0.6050\n",
      "  f1: 0.5982\n",
      "  auc_prc: 0.6906\n",
      "  auc_roc: 0.9657\n",
      "\n",
      "Fold 2:\n",
      "  accuracy: 70.0000\n",
      "  precision: 0.7398\n",
      "  recall: 0.7000\n",
      "  f1: 0.6968\n",
      "  auc_prc: 0.7956\n",
      "  auc_roc: 0.9775\n",
      "\n",
      "Fold 3:\n",
      "  accuracy: 73.7500\n",
      "  precision: 0.7688\n",
      "  recall: 0.7375\n",
      "  f1: 0.7365\n",
      "  auc_prc: 0.8291\n",
      "  auc_roc: 0.9882\n",
      "\n",
      "Fold 4:\n",
      "  accuracy: 70.5000\n",
      "  precision: 0.7409\n",
      "  recall: 0.7050\n",
      "  f1: 0.7014\n",
      "  auc_prc: 0.7918\n",
      "  auc_roc: 0.9770\n",
      "\n",
      "Fold 5:\n",
      "  accuracy: 61.0000\n",
      "  precision: 0.6586\n",
      "  recall: 0.6100\n",
      "  f1: 0.6082\n",
      "  auc_prc: 0.6919\n",
      "  auc_roc: 0.9588\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  accuracy: 67.1500\n",
      "  precision: 0.7167\n",
      "  recall: 0.6715\n",
      "  f1: 0.6682\n",
      "  auc_prc: 0.7598\n",
      "  auc_roc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "labeled_fraction = 0.2\n",
    "split_dir = \"labeled-unlabeled\"\n",
    "\n",
    "fold_accuracies = []\n",
    "fold_metrics = []\n",
    "\n",
    "save_dir = \"models/ESC-50/FlatMatch\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(\"models/ESC-50/FlatMatchnew\", exist_ok=True)\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Load data\n",
    "    labeled_loader, unlabeled_loader, val_loader = get_ssl_loaders(\n",
    "        meta_df=meta_df,\n",
    "        labeled_fraction=labeled_fraction,\n",
    "        fold=fold,\n",
    "        batch_size=batch_size,\n",
    "        split_dir=split_dir\n",
    "    )\n",
    "\n",
    "    model = ESC50CNN(num_classes=50).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_metrics = None\n",
    "    model_path = os.path.join(save_dir, f\"best_model_fold{fold}.pt\")\n",
    "\n",
    "    # Try loading existing model\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Found saved model for Fold {fold}. Loading checkpoint...\")\n",
    "        checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        best_acc = checkpoint.get('metrics', {}).get('accuracy', 0.0)\n",
    "        best_metrics = checkpoint.get('metrics')\n",
    "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(start_epoch, num_epochs + start_epoch):\n",
    "        train_flatmatch_one_epoch(\n",
    "            model=model,\n",
    "            labeled_loader=labeled_loader,\n",
    "            unlabeled_loader=unlabeled_loader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            rho=0.1\n",
    "        )\n",
    "\n",
    "        metrics = evaluate(\n",
    "            encoder=model,\n",
    "            classifier=nn.Identity(),\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            num_classes=50,\n",
    "            plot_loss_curves=False\n",
    "        )\n",
    "\n",
    "        acc = metrics[\"accuracy\"]\n",
    "        print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_metrics = metrics\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'fold': fold,\n",
    "                'epoch': epoch,\n",
    "                'metrics': best_metrics\n",
    "            }, os.path.join(\"models/ESC-50/FlatMatchnew\", f\"best_model_fold{fold}.pt\"))\n",
    "            print(f\"Saved best model for Fold {fold} at epoch {epoch}\")\n",
    "\n",
    "    fold_accuracies.append(best_acc)\n",
    "    fold_metrics.append(best_metrics)\n",
    "    print(f\"Best accuracy for Fold {fold}: {best_acc:.2f}%\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== 5-Fold Summary ===\")\n",
    "avg_metrics = {}\n",
    "\n",
    "for i, m in enumerate(fold_metrics, 1):\n",
    "    print(f\"\\nFold {i}:\")\n",
    "    for k, v in m.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "        avg_metrics[k] = avg_metrics.get(k, 0.0) + (v if v is not None else 0.0)\n",
    "\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "for k, total in avg_metrics.items():\n",
    "    avg_val = total / len(fold_metrics)\n",
    "    print(f\"  {k}: {avg_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79553b5f-0897-46a1-a0a6-cd8ed845a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Arnav\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15271f67-5e9a-4cc6-8025-abfad951edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.6.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\arnav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d988f7-508d-4d93-94b5-07b7be569162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 13 10:56:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.07                 Driver Version: 566.07         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P0             16W /   75W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69965891-3f6f-4395-b97a-f0d548c7ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_full_esc50(model_path, meta_df, batch_size=16, device=None):\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import classification_report\n",
    "    from torch.utils.data import DataLoader\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Create full dataset (no augmentations)\n",
    "    full_dataset = ESC50Dataset(meta_df, augment_type='none')\n",
    "    full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load model\n",
    "    model = ESC50CNN(num_classes=50).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(full_loader, desc=\"Evaluating on full ESC-50\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(y.cpu())\n",
    "\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_true = torch.cat(all_targets).numpy()\n",
    "\n",
    "    print(\"\\nClassification Report on Full ESC-50:\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": report['accuracy'],\n",
    "        \"precision\": report['macro avg']['precision'],\n",
    "        \"recall\": report['macro avg']['recall'],\n",
    "        \"f1\": report['macro avg']['f1-score']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87c42d3-55f1-456e-8e2e-53c5de1d62f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Fold 1 Model on Full ESC-50 Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Evaluating on full ESC-50: 100%|█████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.31it/s]\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Full ESC-50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7436    0.7250    0.7342        40\n",
      "           1     0.9000    0.9000    0.9000        40\n",
      "           2     0.7941    0.6750    0.7297        40\n",
      "           3     0.8333    0.7500    0.7895        40\n",
      "           4     0.7059    0.6000    0.6486        40\n",
      "           5     0.8125    0.6500    0.7222        40\n",
      "           6     0.6444    0.7250    0.6824        40\n",
      "           7     0.7097    0.5500    0.6197        40\n",
      "           8     0.7838    0.7250    0.7532        40\n",
      "           9     0.8500    0.8500    0.8500        40\n",
      "          10     0.5357    0.7500    0.6250        40\n",
      "          11     0.8846    0.5750    0.6970        40\n",
      "          12     0.8750    0.5250    0.6562        40\n",
      "          13     0.7727    0.4250    0.5484        40\n",
      "          14     0.6154    0.8000    0.6957        40\n",
      "          15     0.6897    0.5000    0.5797        40\n",
      "          16     0.6000    0.5250    0.5600        40\n",
      "          17     0.3370    0.7750    0.4697        40\n",
      "          18     0.8750    0.7000    0.7778        40\n",
      "          19     0.7292    0.8750    0.7955        40\n",
      "          20     0.7170    0.9500    0.8172        40\n",
      "          21     0.6809    0.8000    0.7356        40\n",
      "          22     0.6977    0.7500    0.7229        40\n",
      "          23     0.5227    0.5750    0.5476        40\n",
      "          24     0.6042    0.7250    0.6591        40\n",
      "          25     0.5652    0.6500    0.6047        40\n",
      "          26     0.5532    0.6500    0.5977        40\n",
      "          27     0.6452    0.5000    0.5634        40\n",
      "          28     0.8947    0.4250    0.5763        40\n",
      "          29     0.8421    0.4000    0.5424        40\n",
      "          30     0.7708    0.9250    0.8409        40\n",
      "          31     0.6842    0.6500    0.6667        40\n",
      "          32     0.4605    0.8750    0.6034        40\n",
      "          33     0.6087    0.3500    0.4444        40\n",
      "          34     0.5862    0.8500    0.6939        40\n",
      "          35     0.5122    0.5250    0.5185        40\n",
      "          36     0.5455    0.6000    0.5714        40\n",
      "          37     0.8750    0.5250    0.6562        40\n",
      "          38     0.8065    0.6250    0.7042        40\n",
      "          39     0.6341    0.6500    0.6420        40\n",
      "          40     0.4857    0.4250    0.4533        40\n",
      "          41     0.7143    0.7500    0.7317        40\n",
      "          42     0.8000    0.7000    0.7467        40\n",
      "          43     0.7027    0.6500    0.6753        40\n",
      "          44     0.6667    0.3000    0.4138        40\n",
      "          45     0.4500    0.6750    0.5400        40\n",
      "          46     0.6939    0.8500    0.7640        40\n",
      "          47     0.5000    0.5500    0.5238        40\n",
      "          48     0.5278    0.4750    0.5000        40\n",
      "          49     0.8205    0.8000    0.8101        40\n",
      "\n",
      "    accuracy                         0.6555      2000\n",
      "   macro avg     0.6852    0.6555    0.6540      2000\n",
      "weighted avg     0.6852    0.6555    0.6540      2000\n",
      "\n",
      "Fold 1 Metrics: {'accuracy': 0.6555, 'precision': 0.6851923867707989, 'recall': 0.6555, 'f1': 0.6540366500963397}\n",
      "\n",
      "=== Evaluating Fold 2 Model on Full ESC-50 Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on full ESC-50: 100%|█████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.33it/s]\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Full ESC-50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.7000    0.6829        40\n",
      "           1     0.8182    0.9000    0.8571        40\n",
      "           2     0.8846    0.5750    0.6970        40\n",
      "           3     0.9524    0.5000    0.6557        40\n",
      "           4     0.7045    0.7750    0.7381        40\n",
      "           5     0.7778    0.7000    0.7368        40\n",
      "           6     0.6897    0.5000    0.5797        40\n",
      "           7     0.5641    0.5500    0.5570        40\n",
      "           8     0.9524    0.5000    0.6557        40\n",
      "           9     0.8333    0.8750    0.8537        40\n",
      "          10     0.6512    0.7000    0.6747        40\n",
      "          11     0.7000    0.7000    0.7000        40\n",
      "          12     0.7500    0.6000    0.6667        40\n",
      "          13     0.5588    0.4750    0.5135        40\n",
      "          14     0.5254    0.7750    0.6263        40\n",
      "          15     0.6667    0.5000    0.5714        40\n",
      "          16     0.8261    0.4750    0.6032        40\n",
      "          17     0.7955    0.8750    0.8333        40\n",
      "          18     0.9286    0.6500    0.7647        40\n",
      "          19     0.7600    0.9500    0.8444        40\n",
      "          20     0.7115    0.9250    0.8043        40\n",
      "          21     0.7727    0.8500    0.8095        40\n",
      "          22     0.6829    0.7000    0.6914        40\n",
      "          23     0.7500    0.4500    0.5625        40\n",
      "          24     0.7000    0.7000    0.7000        40\n",
      "          25     0.5510    0.6750    0.6067        40\n",
      "          26     0.5161    0.8000    0.6275        40\n",
      "          27     0.7045    0.7750    0.7381        40\n",
      "          28     0.6522    0.7500    0.6977        40\n",
      "          29     0.4727    0.6500    0.5474        40\n",
      "          30     0.6909    0.9500    0.8000        40\n",
      "          31     0.6667    0.6000    0.6316        40\n",
      "          32     0.5763    0.8500    0.6869        40\n",
      "          33     0.7500    0.3750    0.5000        40\n",
      "          34     0.7692    0.7500    0.7595        40\n",
      "          35     0.5714    0.5000    0.5333        40\n",
      "          36     0.7143    0.6250    0.6667        40\n",
      "          37     0.9655    0.7000    0.8116        40\n",
      "          38     0.7027    0.6500    0.6753        40\n",
      "          39     0.6818    0.7500    0.7143        40\n",
      "          40     0.5333    0.4000    0.4571        40\n",
      "          41     0.5965    0.8500    0.7010        40\n",
      "          42     0.8000    0.8000    0.8000        40\n",
      "          43     0.5000    0.5000    0.5000        40\n",
      "          44     0.7407    0.5000    0.5970        40\n",
      "          45     0.4194    0.6500    0.5098        40\n",
      "          46     0.5862    0.8500    0.6939        40\n",
      "          47     0.5400    0.6750    0.6000        40\n",
      "          48     0.8500    0.4250    0.5667        40\n",
      "          49     0.6977    0.7500    0.7229        40\n",
      "\n",
      "    accuracy                         0.6740      2000\n",
      "   macro avg     0.6974    0.6740    0.6705      2000\n",
      "weighted avg     0.6974    0.6740    0.6705      2000\n",
      "\n",
      "Fold 2 Metrics: {'accuracy': 0.674, 'precision': 0.6974449989535926, 'recall': 0.6739999999999999, 'f1': 0.6704929176949307}\n",
      "\n",
      "=== Evaluating Fold 3 Model on Full ESC-50 Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on full ESC-50: 100%|█████████████████████████████████████████████████████| 125/125 [00:53<00:00,  2.32it/s]\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arnav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Full ESC-50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7714    0.6750    0.7200        40\n",
      "           1     0.7778    0.8750    0.8235        40\n",
      "           2     0.9583    0.5750    0.7188        40\n",
      "           3     0.7647    0.6500    0.7027        40\n",
      "           4     0.6744    0.7250    0.6988        40\n",
      "           5     0.7273    0.6000    0.6575        40\n",
      "           6     0.6458    0.7750    0.7045        40\n",
      "           7     0.8214    0.5750    0.6765        40\n",
      "           8     0.8519    0.5750    0.6866        40\n",
      "           9     0.8919    0.8250    0.8571        40\n",
      "          10     0.4194    0.6500    0.5098        40\n",
      "          11     0.8571    0.6000    0.7059        40\n",
      "          12     0.7941    0.6750    0.7297        40\n",
      "          13     0.7857    0.5500    0.6471        40\n",
      "          14     0.7209    0.7750    0.7470        40\n",
      "          15     0.4894    0.5750    0.5287        40\n",
      "          16     0.5789    0.5500    0.5641        40\n",
      "          17     0.8378    0.7750    0.8052        40\n",
      "          18     0.7200    0.9000    0.8000        40\n",
      "          19     0.8409    0.9250    0.8810        40\n",
      "          20     0.5352    0.9500    0.6847        40\n",
      "          21     0.5918    0.7250    0.6517        40\n",
      "          22     0.6596    0.7750    0.7126        40\n",
      "          23     0.8148    0.5500    0.6567        40\n",
      "          24     0.7209    0.7750    0.7470        40\n",
      "          25     0.8387    0.6500    0.7324        40\n",
      "          26     0.6136    0.6750    0.6429        40\n",
      "          27     0.4776    0.8000    0.5981        40\n",
      "          28     0.7879    0.6500    0.7123        40\n",
      "          29     0.6389    0.5750    0.6053        40\n",
      "          30     0.9143    0.8000    0.8533        40\n",
      "          31     0.7692    0.5000    0.6061        40\n",
      "          32     0.6250    0.8750    0.7292        40\n",
      "          33     0.4737    0.4500    0.4615        40\n",
      "          34     0.5517    0.8000    0.6531        40\n",
      "          35     0.4681    0.5500    0.5057        40\n",
      "          36     0.6923    0.6750    0.6835        40\n",
      "          37     0.8444    0.9500    0.8941        40\n",
      "          38     0.7105    0.6750    0.6923        40\n",
      "          39     0.4677    0.7250    0.5686        40\n",
      "          40     0.6316    0.3000    0.4068        40\n",
      "          41     0.8333    0.5000    0.6250        40\n",
      "          42     0.8824    0.7500    0.8108        40\n",
      "          43     0.6486    0.6000    0.6234        40\n",
      "          44     0.8182    0.4500    0.5806        40\n",
      "          45     0.5085    0.7500    0.6061        40\n",
      "          46     0.8333    0.8750    0.8537        40\n",
      "          47     0.4151    0.5500    0.4731        40\n",
      "          48     0.7778    0.3500    0.4828        40\n",
      "          49     0.7714    0.6750    0.7200        40\n",
      "\n",
      "    accuracy                         0.6750      2000\n",
      "   macro avg     0.7049    0.6750    0.6748      2000\n",
      "weighted avg     0.7049    0.6750    0.6748      2000\n",
      "\n",
      "Fold 3 Metrics: {'accuracy': 0.675, 'precision': 0.7049117239041113, 'recall': 0.6749999999999998, 'f1': 0.6747578196192798}\n",
      "\n",
      "=== Evaluating Fold 4 Model on Full ESC-50 Dataset ===\n",
      "Model not found at models/ESC-50/FlatMatchnew/best_model_fold4.pt, skipping...\n",
      "\n",
      "=== Evaluating Fold 5 Model on Full ESC-50 Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on full ESC-50: 100%|█████████████████████████████████████████████████████| 125/125 [00:54<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Full ESC-50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.6000    0.7164        40\n",
      "           1     0.8605    0.9250    0.8916        40\n",
      "           2     0.8500    0.4250    0.5667        40\n",
      "           3     0.8387    0.6500    0.7324        40\n",
      "           4     0.6809    0.8000    0.7356        40\n",
      "           5     0.5778    0.6500    0.6118        40\n",
      "           6     0.6875    0.5500    0.6111        40\n",
      "           7     0.9444    0.4250    0.5862        40\n",
      "           8     0.7941    0.6750    0.7297        40\n",
      "           9     0.7317    0.7500    0.7407        40\n",
      "          10     0.8571    0.7500    0.8000        40\n",
      "          11     0.8125    0.6500    0.7222        40\n",
      "          12     0.7143    0.7500    0.7317        40\n",
      "          13     0.5946    0.5500    0.5714        40\n",
      "          14     0.6500    0.6500    0.6500        40\n",
      "          15     0.5938    0.4750    0.5278        40\n",
      "          16     0.6333    0.4750    0.5429        40\n",
      "          17     0.8378    0.7750    0.8052        40\n",
      "          18     0.5882    1.0000    0.7407        40\n",
      "          19     0.8537    0.8750    0.8642        40\n",
      "          20     0.8293    0.8500    0.8395        40\n",
      "          21     0.8000    0.8000    0.8000        40\n",
      "          22     0.5738    0.8750    0.6931        40\n",
      "          23     0.4444    0.7000    0.5437        40\n",
      "          24     0.7692    0.5000    0.6061        40\n",
      "          25     0.5490    0.7000    0.6154        40\n",
      "          26     0.5577    0.7250    0.6304        40\n",
      "          27     0.8261    0.4750    0.6032        40\n",
      "          28     0.6042    0.7250    0.6591        40\n",
      "          29     0.5278    0.4750    0.5000        40\n",
      "          30     0.7660    0.9000    0.8276        40\n",
      "          31     0.7333    0.5500    0.6286        40\n",
      "          32     0.7021    0.8250    0.7586        40\n",
      "          33     0.8000    0.3000    0.4364        40\n",
      "          34     0.6875    0.8250    0.7500        40\n",
      "          35     0.6400    0.4000    0.4923        40\n",
      "          36     0.8182    0.6750    0.7397        40\n",
      "          37     0.9667    0.7250    0.8286        40\n",
      "          38     0.4737    0.6750    0.5567        40\n",
      "          39     0.5714    0.8000    0.6667        40\n",
      "          40     0.2619    0.5500    0.3548        40\n",
      "          41     0.5306    0.6500    0.5843        40\n",
      "          42     0.8929    0.6250    0.7353        40\n",
      "          43     0.6774    0.5250    0.5915        40\n",
      "          44     0.7143    0.3750    0.4918        40\n",
      "          45     0.5102    0.6250    0.5618        40\n",
      "          46     0.8500    0.8500    0.8500        40\n",
      "          47     0.3571    0.5000    0.4167        40\n",
      "          48     0.5250    0.5250    0.5250        40\n",
      "          49     0.8049    0.8250    0.8148        40\n",
      "\n",
      "    accuracy                         0.6590      2000\n",
      "   macro avg     0.6951    0.6590    0.6596      2000\n",
      "weighted avg     0.6951    0.6590    0.6596      2000\n",
      "\n",
      "Fold 5 Metrics: {'accuracy': 0.659, 'precision': 0.6950888265638336, 'recall': 0.659, 'f1': 0.6595983221457861}\n",
      "\n",
      "=== Average Performance on Full ESC-50 (by fold models) ===\n",
      "accuracy: 0.6659\n",
      "precision: 0.6957\n",
      "recall: 0.6659\n",
      "f1: 0.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fold_metrics = []\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n=== Evaluating Fold {fold} Model on Full ESC-50 Dataset ===\")\n",
    "    model_path = f\"models/ESC-50/FlatMatchnew/best_model_fold{fold}.pt\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    metrics = evaluate_model_on_full_esc50(\n",
    "        model_path=model_path,\n",
    "        meta_df=meta_df,\n",
    "        batch_size=16\n",
    "    )\n",
    "    \n",
    "    fold_metrics.append((fold, metrics))\n",
    "    print(f\"Fold {fold} Metrics: {metrics}\")\n",
    "\n",
    "# Average metrics across folds\n",
    "print(\"\\n=== Average Performance on Full ESC-50 (by fold models) ===\")\n",
    "avg_metrics = {}\n",
    "for _, m in fold_metrics:\n",
    "    for k, v in m.items():\n",
    "        avg_metrics[k] = avg_metrics.get(k, 0.0) + v\n",
    "\n",
    "for k, v in avg_metrics.items():\n",
    "    print(f\"{k}: {v / len(fold_metrics):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534fd1ef-1883-480c-af4c-610cab407210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
