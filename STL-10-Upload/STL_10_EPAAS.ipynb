{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L54W57cg-yrD"
      },
      "outputs": [],
      "source": [
        "# Part 1: Imports and Initial Setup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import KFold\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "import json\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from typing import Tuple, Dict, Any, List\n",
        "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('epaas_training.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Constants\n",
        "SEED = 42\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 5\n",
        "BASE_LR = 0.03\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Set device and random seeds\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# Create necessary directories\n",
        "def create_directories(base_path=\"/content/drive/MyDrive/Epaas\"):\n",
        "    base = Path(base_path)\n",
        "    dirs = ['checkpoints', 'results', 'logs']\n",
        "\n",
        "    # Create base directory if it doesn't exist\n",
        "    base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create subdirectories under base path\n",
        "    directories = {}\n",
        "    for dir_name in dirs:\n",
        "        dir_path = base / dir_name\n",
        "        dir_path.mkdir(parents=True, exist_ok=True)\n",
        "        directories[dir_name] = dir_path\n",
        "\n",
        "    return directories\n",
        "\n",
        "directories = create_directories()\n",
        "\n",
        "\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class for hyperparameters\"\"\"\n",
        "    def __init__(self):\n",
        "        self.num_classes = NUM_CLASSES\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.num_epochs = NUM_EPOCHS\n",
        "        self.base_lr = BASE_LR\n",
        "        self.momentum = MOMENTUM\n",
        "        self.weight_decay = WEIGHT_DECAY\n",
        "        self.num_workers = NUM_WORKERS\n",
        "        self.device = device\n",
        "\n",
        "        # EPAAS specific parameters\n",
        "        self.initial_threshold = 0.95\n",
        "        self.final_threshold = 0.8\n",
        "        self.temperature = 1.0\n",
        "        self.alpha = 0.5  # Weight for entropy minimization\n",
        "        self.beta = 1.0   # Weight for consistency regularization\n",
        "\n",
        "        # Training specific\n",
        "        self.num_folds = 5\n",
        "        self.early_stopping_patience = 10\n",
        "        self.gradient_clip_val = 1.0\n",
        "\n",
        "config = Config()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Data Loading and Augmentation\n",
        "\n",
        "class AdvancedAugmentation:\n",
        "    \"\"\"\n",
        "    Advanced augmentation pipeline for EPAAS with weak and strong augmentations\n",
        "    \"\"\"\n",
        "    def __init__(self, size=96, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
        "        self.weak = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomCrop(size, padding=4, padding_mode='reflect'),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=0.2,\n",
        "                contrast=0.2,\n",
        "                saturation=0.2,\n",
        "                hue=0.1\n",
        "            ),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "        self.strong = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomCrop(size, padding=4, padding_mode='reflect'),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=0.4,\n",
        "                contrast=0.4,\n",
        "                saturation=0.4,\n",
        "                hue=0.2\n",
        "            ),\n",
        "            transforms.RandomRotation(20),\n",
        "            transforms.RandomAffine(\n",
        "                degrees=0,\n",
        "                translate=(0.1, 0.1),\n",
        "                scale=(0.9, 1.1),\n",
        "                shear=5\n",
        "            ),\n",
        "            transforms.RandomApply([\n",
        "                transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
        "            ], p=0.3),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "        self.test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "class STL10Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom STL10 Dataset with flexible transformation handling\n",
        "    \"\"\"\n",
        "    def __init__(self, root, split='train', transform=None, download=True):\n",
        "        self.dataset = torchvision.datasets.STL10(\n",
        "            root=root,\n",
        "            split=split,\n",
        "            transform=None,\n",
        "            download=download\n",
        "        )\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            if isinstance(self.transform, dict):\n",
        "                # Multiple augmentations\n",
        "                augmented = {k: t(image) for k, t in self.transform.items()}\n",
        "                return augmented, label\n",
        "            else:\n",
        "                # Single augmentation\n",
        "                return self.transform(image), label\n",
        "        return image, label\n",
        "\n",
        "class DataPrefetcher:\n",
        "    \"\"\"\n",
        "    Data prefetcher for faster data loading\n",
        "    \"\"\"\n",
        "    def __init__(self, loader):\n",
        "        self.loader = iter(loader)\n",
        "        self.stream = torch.cuda.Stream()\n",
        "        self.preload()\n",
        "\n",
        "    def preload(self):\n",
        "        try:\n",
        "            self.next_data = next(self.loader)\n",
        "        except StopIteration:\n",
        "            self.next_data = None\n",
        "            return\n",
        "\n",
        "        with torch.cuda.stream(self.stream):\n",
        "            if isinstance(self.next_data[0], dict):\n",
        "                self.next_data = (\n",
        "                    {k: v.cuda(non_blocking=True)\n",
        "                     for k, v in self.next_data[0].items()},\n",
        "                    self.next_data[1].cuda(non_blocking=True)\n",
        "                )\n",
        "            else:\n",
        "                self.next_data = (\n",
        "                    self.next_data[0].cuda(non_blocking=True),\n",
        "                    self.next_data[1].cuda(non_blocking=True)\n",
        "                )\n",
        "\n",
        "    def next(self):\n",
        "        torch.cuda.current_stream().wait_stream(self.stream)\n",
        "        data = self.next_data\n",
        "        self.preload()\n",
        "        return data\n",
        "\n",
        "def get_stl10_dataloaders(config):\n",
        "    \"\"\"\n",
        "    Get STL10 dataloaders with appropriate transformations\n",
        "    \"\"\"\n",
        "    data_dir = Path(\"/content/drive/MyDrive/Epaas/data/STL10\")\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    augmentation = AdvancedAugmentation()\n",
        "\n",
        "    try:\n",
        "        # Training dataset with both weak and strong augmentations\n",
        "        train_dataset = STL10Dataset(\n",
        "            root=data_dir,\n",
        "            split='train',\n",
        "            transform={\n",
        "                'weak': augmentation.weak,\n",
        "                'strong': augmentation.strong\n",
        "            },\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        # Validation dataset with only weak augmentation\n",
        "        val_dataset = STL10Dataset(\n",
        "            root=data_dir,\n",
        "            split='train',\n",
        "            transform=augmentation.weak,  # Only weak augmentation for validation\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        # Unlabeled dataset with both augmentations\n",
        "        unlabeled_dataset = STL10Dataset(\n",
        "            root=data_dir,\n",
        "            split='unlabeled',\n",
        "            transform={\n",
        "                'weak': augmentation.weak,\n",
        "                'strong': augmentation.strong\n",
        "            },\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        # Test dataset with test transformation\n",
        "        test_dataset = STL10Dataset(\n",
        "            root=data_dir,\n",
        "            split='test',\n",
        "            transform=augmentation.test,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        # Create train-validation split\n",
        "        train_size = int(0.8 * len(train_dataset))\n",
        "        val_size = len(train_dataset) - train_size\n",
        "\n",
        "        train_subset, val_subset = torch.utils.data.random_split(\n",
        "            train_dataset,\n",
        "            [train_size, val_size],\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "\n",
        "        # Create dataloaders\n",
        "        train_loader = DataLoader(\n",
        "            train_subset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=config.num_workers,\n",
        "            pin_memory=True,\n",
        "            drop_last=True\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_subset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=config.num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        unlabeled_loader = DataLoader(\n",
        "            unlabeled_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=config.num_workers,\n",
        "            pin_memory=True,\n",
        "            drop_last=True\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=config.num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'train': train_loader,\n",
        "            'val': val_loader,\n",
        "            'unlabeled': unlabeled_loader,\n",
        "            'test': test_loader\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in data loading: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "\n",
        "def verify_data_pipeline(dataloaders):\n",
        "    \"\"\"\n",
        "    Verify the data pipeline by checking a batch of data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check training data\n",
        "        train_batch, train_labels = next(iter(dataloaders['train']))\n",
        "        logging.info(f\"Training batch shapes:\")\n",
        "        logging.info(f\"Weak augmentation: {train_batch['weak'].shape}\")\n",
        "        logging.info(f\"Strong augmentation: {train_batch['strong'].shape}\")\n",
        "        logging.info(f\"Labels: {train_labels.shape}\")\n",
        "\n",
        "        # Check unlabeled data\n",
        "        unlabeled_batch, _ = next(iter(dataloaders['unlabeled']))\n",
        "        logging.info(f\"\\nUnlabeled batch shapes:\")\n",
        "        logging.info(f\"Weak augmentation: {unlabeled_batch['weak'].shape}\")\n",
        "        logging.info(f\"Strong augmentation: {unlabeled_batch['strong'].shape}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in data pipeline verification: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test data pipeline\n",
        "    dataloaders = get_stl10_dataloaders(config)\n",
        "    if verify_data_pipeline(dataloaders):\n",
        "        logging.info(\"Data pipeline verification successful!\")\n",
        "    else:\n",
        "        logging.error(\"Data pipeline verification failed!\")\n"
      ],
      "metadata": {
        "id": "eROXqdBY-4kA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Model Architecture and Loss Functions\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified ResNet18 architecture for EPAAS\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10, pretrained=True, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        # Load pretrained ResNet18\n",
        "        self.model = torchvision.models.resnet18(pretrained=pretrained)\n",
        "\n",
        "        # Modify the first conv layer for STL-10 image size\n",
        "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.model.maxpool = nn.Identity()  # Remove maxpool layer\n",
        "\n",
        "        # Modify final layers\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        # Initialize the new layers\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.model.fc.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class EPAASLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    EPAAS Loss implementation with entropy-based pseudo-label selection\n",
        "    and adaptive thresholding\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, initial_threshold=0.95, temperature=1.0,\n",
        "                 alpha=0.5, beta=1.0):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.threshold = initial_threshold\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha  # Weight for entropy minimization\n",
        "        self.beta = beta    # Weight for consistency regularization\n",
        "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def entropy(self, probs):\n",
        "        \"\"\"Calculate entropy of probability distributions\"\"\"\n",
        "        return -torch.sum(probs * torch.log(probs + 1e-6), dim=1)\n",
        "\n",
        "    def consistency_loss(self, logits_w, logits_s):\n",
        "        \"\"\"Calculate consistency loss between weak and strong augmentations\"\"\"\n",
        "        return F.mse_loss(\n",
        "            torch.softmax(logits_s, dim=1),\n",
        "            torch.softmax(logits_w, dim=1),\n",
        "            reduction='none'\n",
        "        ).mean(1)\n",
        "\n",
        "    def forward(self, logits_w, logits_s, current_epoch=None, total_epochs=None):\n",
        "        \"\"\"\n",
        "        Forward pass of EPAAS loss\n",
        "        Args:\n",
        "            logits_w: Logits from weakly augmented images\n",
        "            logits_s: Logits from strongly augmented images\n",
        "            current_epoch: Current training epoch (for threshold adjustment)\n",
        "            total_epochs: Total number of epochs\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Calculate probabilities and entropy for weak augmentation\n",
        "            probs_w = torch.softmax(logits_w / self.temperature, dim=1)\n",
        "            entropy_w = self.entropy(probs_w)\n",
        "\n",
        "            # Adaptive threshold based on entropy and training progress\n",
        "            entropy_mean = entropy_w.mean()\n",
        "            base_threshold = self.threshold\n",
        "            if current_epoch is not None and total_epochs is not None:\n",
        "                # Gradually decrease threshold\n",
        "                progress = current_epoch / total_epochs\n",
        "                base_threshold = self.threshold * (1 - 0.2 * progress)\n",
        "\n",
        "            adaptive_threshold = base_threshold * (1 - entropy_mean/np.log(self.num_classes))\n",
        "\n",
        "            # Get pseudo-labels and confidence mask\n",
        "            max_probs, pseudo_labels = torch.max(probs_w, dim=1)\n",
        "            mask = max_probs.ge(adaptive_threshold)\n",
        "\n",
        "            # Calculate auto-sampling weights based on entropy\n",
        "            weights = 1 - entropy_w/np.log(self.num_classes)\n",
        "            weights = weights / weights.mean()  # normalize weights\n",
        "\n",
        "        # Supervised loss with pseudo-labels\n",
        "        loss_s = self.cross_entropy(logits_s, pseudo_labels)\n",
        "        loss_s = (loss_s * mask.float() * weights).mean()\n",
        "\n",
        "        # Entropy minimization loss\n",
        "        probs_s = torch.softmax(logits_s / self.temperature, dim=1)\n",
        "        entropy_s = self.entropy(probs_s)\n",
        "        loss_ent = entropy_s.mean()\n",
        "\n",
        "        # Consistency regularization loss\n",
        "        loss_cons = self.consistency_loss(logits_w, logits_s)\n",
        "        loss_cons = (loss_cons * weights).mean()\n",
        "\n",
        "        # Combined loss with adaptive weights\n",
        "        total_loss = loss_s + self.alpha * loss_ent + self.beta * loss_cons\n",
        "\n",
        "        return {\n",
        "            'total_loss': total_loss,\n",
        "            'pseudo_loss': loss_s,\n",
        "            'entropy_loss': loss_ent,\n",
        "            'consistency_loss': loss_cons,\n",
        "            'mask_mean': mask.float().mean(),\n",
        "            'threshold': adaptive_threshold\n",
        "        }\n",
        "\n",
        "class SupervisedLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Supervised loss component for labeled data\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        return self.cross_entropy(logits, targets)\n",
        "\n",
        "class LossTracker:\n",
        "    \"\"\"\n",
        "    Utility class to track and log different loss components\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.losses = {\n",
        "            'total_loss': [],\n",
        "            'pseudo_loss': [],\n",
        "            'entropy_loss': [],\n",
        "            'consistency_loss': [],\n",
        "            'supervised_loss': [],\n",
        "            'mask_mean': [],\n",
        "            'threshold': []\n",
        "        }\n",
        "\n",
        "    def update(self, loss_dict):\n",
        "        for key, value in loss_dict.items():\n",
        "            if key in self.losses:\n",
        "                self.losses[key].append(value.item() if torch.is_tensor(value) else value)\n",
        "\n",
        "    def get_means(self):\n",
        "        return {key: np.mean(values) for key, values in self.losses.items() if values}\n",
        "\n",
        "    def log_means(self, epoch):\n",
        "        means = self.get_means()\n",
        "        logging.info(f\"\\nEpoch {epoch} Loss Summary:\")\n",
        "        for key, value in means.items():\n",
        "            logging.info(f\"{key}: {value:.4f}\")\n",
        "\n",
        "def initialize_model(config):\n",
        "    \"\"\"\n",
        "    Initialize model and loss functions\n",
        "    \"\"\"\n",
        "    model = ResNet18(\n",
        "        num_classes=config.num_classes,\n",
        "        pretrained=True,\n",
        "        dropout_rate=0.3\n",
        "    ).to(config.device)\n",
        "\n",
        "    epaas_loss = EPAASLoss(\n",
        "        num_classes=config.num_classes,\n",
        "        initial_threshold=config.initial_threshold,\n",
        "        temperature=config.temperature,\n",
        "        alpha=config.alpha,\n",
        "        beta=config.beta\n",
        "    ).to(config.device)\n",
        "\n",
        "    supervised_loss = SupervisedLoss(\n",
        "        num_classes=config.num_classes\n",
        "    ).to(config.device)\n",
        "\n",
        "    return model, epaas_loss, supervised_loss\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test model and loss functions\n",
        "    model, epaas_loss, supervised_loss = initialize_model(config)\n",
        "\n",
        "    # Print model summary\n",
        "    logging.info(\"\\nModel Architecture:\")\n",
        "    logging.info(model)\n",
        "\n",
        "    # Calculate model parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    logging.info(f\"\\nTotal parameters: {total_params:,}\")\n",
        "    logging.info(f\"Trainable parameters: {trainable_params:,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0NS7jbo_Zkm",
        "outputId": "70c38969-278b-41e0-b3a7-26e64a920a5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 172MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Training Components\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Early stopping handler with model checkpoint saving\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=7, min_delta=1e-4, mode='min', verbose=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.mode = mode\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model = deepcopy(model.state_dict())\n",
        "        elif (self.mode == 'min' and val_loss > self.best_loss - self.min_delta) or \\\n",
        "             (self.mode == 'max' and val_loss < self.best_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                logging.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model = deepcopy(model.state_dict())\n",
        "            self.counter = 0\n",
        "        return self.early_stop\n",
        "\n",
        "class ModelCheckpoint:\n",
        "    \"\"\"\n",
        "    Model checkpoint handler with multiple metric monitoring\n",
        "    \"\"\"\n",
        "    def __init__(self, save_dir, metric_name='val_loss', mode='min'):\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.metric_name = metric_name\n",
        "        self.mode = mode\n",
        "        self.best_metric = float('inf') if mode == 'min' else float('-inf')\n",
        "\n",
        "    def __call__(self, model, current_metric, epoch, metrics_dict=None):\n",
        "        improved = (self.mode == 'min' and current_metric < self.best_metric) or \\\n",
        "                  (self.mode == 'max' and current_metric > self.best_metric)\n",
        "\n",
        "        if improved:\n",
        "            self.best_metric = current_metric\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                f'best_{self.metric_name}': self.best_metric,\n",
        "                'metrics': metrics_dict\n",
        "            }\n",
        "            torch.save(checkpoint, self.save_dir / f'best_model_{self.metric_name}.pth')\n",
        "            logging.info(f'Saved new best model with {self.metric_name}: {self.best_metric:.4f}')\n",
        "\n",
        "class MetricsTracker:\n",
        "    \"\"\"\n",
        "    Tracks and computes various metrics during training\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.predictions = []\n",
        "        self.targets = []\n",
        "        self.losses = []\n",
        "\n",
        "    def update(self, preds, targets, loss=None):\n",
        "        self.predictions.extend(preds.cpu().numpy())\n",
        "        self.targets.extend(targets.cpu().numpy())\n",
        "        if loss is not None:\n",
        "            self.losses.append(loss.item())\n",
        "\n",
        "    def compute_metrics(self):\n",
        "        predictions = np.array(self.predictions)\n",
        "        targets = np.array(self.targets)\n",
        "\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(targets, predictions),\n",
        "            'precision': precision_score(targets, predictions, average='macro'),\n",
        "            'recall': recall_score(targets, predictions, average='macro'),\n",
        "            'f1': f1_score(targets, predictions, average='macro')\n",
        "        }\n",
        "\n",
        "        if self.losses:\n",
        "            metrics['loss'] = np.mean(self.losses)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"\n",
        "    Main trainer class for EPAAS\n",
        "    \"\"\"\n",
        "    def __init__(self, model, epaas_loss, supervised_loss, config):\n",
        "        self.model = model\n",
        "        self.epaas_loss = epaas_loss\n",
        "        self.supervised_loss = supervised_loss\n",
        "        self.config = config\n",
        "        self.device = config.device\n",
        "\n",
        "        # Initialize optimizers\n",
        "        self.optimizer = self._create_optimizer()\n",
        "        self.scheduler = self._create_scheduler()\n",
        "\n",
        "        # Initialize trackers\n",
        "        self.loss_tracker = LossTracker()\n",
        "        self.metrics_tracker = MetricsTracker()\n",
        "\n",
        "        # Initialize early stopping and checkpointing\n",
        "        self.early_stopping = EarlyStopping(\n",
        "            patience=config.early_stopping_patience,\n",
        "            mode='max'\n",
        "        )\n",
        "        self.checkpoint = ModelCheckpoint(\n",
        "            save_dir='checkpoints',\n",
        "            metric_name='val_accuracy',\n",
        "            mode='max'\n",
        "        )\n",
        "\n",
        "    def _create_optimizer(self):\n",
        "        return optim.SGD([\n",
        "            {'params': self.model.model.fc.parameters(), 'lr': self.config.base_lr},\n",
        "            {'params': [p for n, p in self.model.model.named_parameters()\n",
        "                       if not n.startswith('fc')],\n",
        "             'lr': self.config.base_lr/10}\n",
        "        ], momentum=self.config.momentum, weight_decay=self.config.weight_decay)\n",
        "\n",
        "    def _create_scheduler(self):\n",
        "        return CosineAnnealingWarmRestarts(\n",
        "            self.optimizer,\n",
        "            T_0=10,\n",
        "            T_mult=2,\n",
        "            eta_min=self.config.base_lr * 0.01\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, val_loader):\n",
        "        \"\"\"\n",
        "        Validate the model\n",
        "\n",
        "        Args:\n",
        "            val_loader (DataLoader): Validation data loader\n",
        "\n",
        "        Returns:\n",
        "            dict: Validation metrics\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        self.metrics_tracker.reset()\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            # Handle inputs that might be dictionary or tensor\n",
        "            if isinstance(inputs, dict):\n",
        "                # Use 'weak' augmentation for validation\n",
        "                inputs = inputs['weak']\n",
        "\n",
        "            # Move to device\n",
        "            inputs = inputs.to(self.device)\n",
        "            targets = targets.to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.supervised_loss(outputs, targets)\n",
        "\n",
        "            # Calculate predictions\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            # Update metrics\n",
        "            self.metrics_tracker.update(predicted, targets, loss)\n",
        "\n",
        "        # Compute and return metrics\n",
        "        metrics = self.metrics_tracker.compute_metrics()\n",
        "        return metrics\n",
        "\n",
        "    def train_epoch(self, train_loader, unlabeled_loader, epoch):\n",
        "        \"\"\"\n",
        "        Train for one epoch\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        self.loss_tracker.reset()\n",
        "        self.metrics_tracker.reset()\n",
        "\n",
        "        unlabeled_iter = iter(unlabeled_loader)\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
        "            # Get unlabeled batch\n",
        "            try:\n",
        "                unlabeled_batch, _ = next(unlabeled_iter)\n",
        "            except StopIteration:\n",
        "                unlabeled_iter = iter(unlabeled_loader)\n",
        "                unlabeled_batch, _ = next(unlabeled_iter)\n",
        "\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs['weak'].to(self.device), targets.to(self.device)\n",
        "            u_w, u_s = unlabeled_batch['weak'].to(self.device), \\\n",
        "                       unlabeled_batch['strong'].to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            labeled_logits = self.model(inputs)\n",
        "            unlabeled_logits_w = self.model(u_w)\n",
        "            unlabeled_logits_s = self.model(u_s)\n",
        "\n",
        "            # Calculate losses\n",
        "            sup_loss = self.supervised_loss(labeled_logits, targets)\n",
        "            unsup_losses = self.epaas_loss(\n",
        "                unlabeled_logits_w,\n",
        "                unlabeled_logits_s,\n",
        "                current_epoch=epoch,\n",
        "                total_epochs=self.config.num_epochs\n",
        "            )\n",
        "\n",
        "            # Combined loss\n",
        "            total_loss = sup_loss + unsup_losses['total_loss']\n",
        "\n",
        "            # Optimization\n",
        "            self.optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                self.model.parameters(),\n",
        "                self.config.gradient_clip_val\n",
        "            )\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Update metrics\n",
        "            _, predicted = labeled_logits.max(1)\n",
        "            self.metrics_tracker.update(predicted, targets, total_loss)\n",
        "\n",
        "            # Update loss tracker\n",
        "            self.loss_tracker.update({\n",
        "                'total_loss': total_loss,\n",
        "                'supervised_loss': sup_loss,\n",
        "                **unsup_losses\n",
        "            })\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': total_loss.item(),\n",
        "                'sup_loss': sup_loss.item(),\n",
        "                'mask_mean': unsup_losses['mask_mean']\n",
        "            })\n",
        "\n",
        "        # Step scheduler\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # Compute epoch metrics\n",
        "        train_metrics = self.metrics_tracker.compute_metrics()\n",
        "        train_metrics.update(self.loss_tracker.get_means())\n",
        "\n",
        "        return train_metrics\n",
        "\n",
        "    def save_training_state(self, epoch, metrics, save_dir):\n",
        "        \"\"\"\n",
        "        Save training state and metrics\n",
        "        \"\"\"\n",
        "        state = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'metrics': metrics\n",
        "        }\n",
        "        torch.save(state, save_dir / f'training_state_epoch_{epoch}.pth')\n",
        "\n",
        "    def load_training_state(self, state_path):\n",
        "        \"\"\"\n",
        "        Load training state\n",
        "        \"\"\"\n",
        "        state = torch.load(state_path)\n",
        "        self.model.load_state_dict(state['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(state['scheduler_state_dict'])\n",
        "        return state['epoch'], state['metrics']\n"
      ],
      "metadata": {
        "id": "CId1WSAX_cc0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 5: Main Training Loop and Results Visualization\n",
        "\n",
        "import logging\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Union\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "class ExperimentManager:\n",
        "    \"\"\"\n",
        "    Manages experiment execution, logging, and visualization with enhanced error handling\n",
        "\n",
        "    Attributes:\n",
        "        config (object): Experiment configuration object\n",
        "        experiment_name (str): Name of the experiment\n",
        "        results_dir (Path): Path to results directory\n",
        "        training_history (dict): Storage for training metrics\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, experiment_name: str = \"EPAAS_STL10\"):\n",
        "        \"\"\"\n",
        "        Initialize ExperimentManager with proper error handling\n",
        "\n",
        "        Args:\n",
        "            config: Experiment configuration object\n",
        "            experiment_name: Name of the experiment (default: \"EPAAS_STL10\")\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.experiment_name = self._sanitize_name(experiment_name)\n",
        "\n",
        "        # Initialize paths safely\n",
        "        self.base_path = Path(\"/content/drive/MyDrive/Epaas/results\")\n",
        "        self.results_dir = self._setup_results_directory()\n",
        "\n",
        "        # Initialize metrics storage\n",
        "        self.training_history = {\n",
        "            'train_metrics': [],\n",
        "            'val_metrics': [],\n",
        "            'best_epoch': 0,\n",
        "            'best_val_accuracy': 0.0\n",
        "        }\n",
        "\n",
        "        # Setup logging\n",
        "        self.logger = self._setup_logging()\n",
        "\n",
        "    def _sanitize_name(self, name: str) -> str:\n",
        "        \"\"\"Sanitize experiment name for file safety\"\"\"\n",
        "        return \"\".join(c for c in name if c.isalnum() or c in ('-', '_')).strip().rstrip()\n",
        "\n",
        "    def _setup_results_directory(self) -> Path:\n",
        "        \"\"\"Create results directory with error handling\"\"\"\n",
        "        try:\n",
        "            results_dir = self.base_path / self.experiment_name\n",
        "            results_dir.mkdir(parents=True, exist_ok=True)\n",
        "            return results_dir\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to create results directory: {str(e)}\")\n",
        "\n",
        "    def _setup_logging(self) -> logging.Logger:\n",
        "        \"\"\"Configure logging with multiple handlers\"\"\"\n",
        "        logger = logging.getLogger(self.experiment_name)\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        # Prevent duplicate handlers\n",
        "        if logger.handlers:\n",
        "            return logger\n",
        "\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "        try:\n",
        "            file_handler = logging.FileHandler(self.results_dir / 'experiment.log')\n",
        "            file_handler.setFormatter(formatter)\n",
        "            logger.addHandler(file_handler)\n",
        "        except IOError as e:\n",
        "            logger.error(f\"Failed to create log file: {str(e)}\")\n",
        "\n",
        "        console_handler = logging.StreamHandler()\n",
        "        console_handler.setFormatter(formatter)\n",
        "        logger.addHandler(console_handler)\n",
        "\n",
        "        logger.info(f\"Starting experiment: {self.experiment_name}\")\n",
        "        logger.info(f\"Config: {self._safe_config_representation()}\")\n",
        "\n",
        "        return logger\n",
        "\n",
        "    def _safe_config_representation(self) -> Dict:\n",
        "        \"\"\"Convert config to safe serializable format\"\"\"\n",
        "        if hasattr(self.config, '__dict__'):\n",
        "            config_dict = vars(self.config)\n",
        "        else:\n",
        "            config_dict = dict(self.config)\n",
        "\n",
        "        # Convert non-serializable values\n",
        "        for k, v in config_dict.items():\n",
        "            if hasattr(v, 'device'):\n",
        "                config_dict[k] = str(v)\n",
        "        return config_dict\n",
        "\n",
        "    def plot_training_curves(self) -> None:\n",
        "        \"\"\"Plot training and validation metrics with safety checks\"\"\"\n",
        "        if not self.training_history['train_metrics']:\n",
        "            self.logger.warning(\"No training metrics to plot\")\n",
        "            return\n",
        "\n",
        "        metrics_to_plot = [\n",
        "            ('accuracy', 'Accuracy'),\n",
        "            ('loss', 'Loss'),\n",
        "            ('mask_mean', 'Pseudo-Label Mask Mean'),\n",
        "            ('threshold', 'Confidence Threshold')\n",
        "        ]\n",
        "\n",
        "        plt.figure(figsize=(20, 15))\n",
        "        for idx, (metric, title) in enumerate(metrics_to_plot, 1):\n",
        "            plt.subplot(2, 2, idx)\n",
        "\n",
        "            # Plot training metrics if available\n",
        "            try:\n",
        "                train_values = [m.get(metric, np.nan) for m in self.training_history['train_metrics']]\n",
        "                plt.plot(train_values, label=f'Train {title}')\n",
        "            except KeyError:\n",
        "                pass\n",
        "\n",
        "            # Plot validation metrics if available\n",
        "            try:\n",
        "                val_values = [m.get(metric, np.nan) for m in self.training_history['val_metrics']]\n",
        "                plt.plot(val_values, label=f'Val {title}')\n",
        "            except KeyError:\n",
        "                pass\n",
        "\n",
        "            plt.title(title)\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel(title)\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        try:\n",
        "            plt.savefig(self.results_dir / 'training_curves.png')\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to save training curves: {str(e)}\")\n",
        "\n",
        "    def plot_confusion_matrix(self, true_labels: List, predictions: List, classes: range = range(10)) -> None:\n",
        "        \"\"\"Generate confusion matrix with input validation\"\"\"\n",
        "        if len(true_labels) != len(predictions):\n",
        "            self.logger.error(\"Mismatch in true labels and predictions length\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            cm = confusion_matrix(true_labels, predictions)\n",
        "            plt.figure(figsize=(12, 10))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                        xticklabels=classes, yticklabels=classes)\n",
        "            plt.title('Confusion Matrix')\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.savefig(self.results_dir / 'confusion_matrix.png')\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to plot confusion matrix: {str(e)}\")\n",
        "\n",
        "    def save_results(self, final_metrics: Dict) -> None:\n",
        "        \"\"\"Save experiment results with serialization safety\"\"\"\n",
        "        results = {\n",
        "            'config': self._safe_config_representation(),\n",
        "            'training_history': self.training_history,\n",
        "            'final_metrics': self._sanitize_metrics(final_metrics),\n",
        "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(self.results_dir / 'results_epaas_stl-10.json', 'w') as f:\n",
        "                json.dump(results, f, indent=4, cls=NumpyEncoder)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to save results: {str(e)}\")\n",
        "\n",
        "    def _sanitize_metrics(self, metrics: Dict) -> Dict:\n",
        "        \"\"\"Convert metrics to JSON-serializable format\"\"\"\n",
        "        return {k: float(v) if isinstance(v, (np.generic, np.ndarray)) else v\n",
        "                for k, v in metrics.items()}\n",
        "\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    \"\"\"Custom encoder for numpy data types\"\"\"\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super().default(obj)\n",
        "\n",
        "def train_fold(trainer, train_loader, val_loader, unlabeled_loader, config, fold_num):\n",
        "    \"\"\"\n",
        "    Train a single fold in k-fold cross validation\n",
        "\n",
        "    Args:\n",
        "        trainer (Trainer): Trainer instance\n",
        "        train_loader (DataLoader): Training data loader\n",
        "        val_loader (DataLoader): Validation data loader\n",
        "        unlabeled_loader (DataLoader): Unlabeled data loader\n",
        "        config (Config): Configuration object\n",
        "        fold_num (int): Current fold number\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing fold training results\n",
        "    \"\"\"\n",
        "    logging.info(f\"\\nTraining Fold {fold_num + 1}\")\n",
        "\n",
        "    # Initialize fold metrics\n",
        "    fold_metrics = {\n",
        "        'train_metrics': [],\n",
        "        'val_metrics': [],\n",
        "        'best_val_accuracy': 0.0,\n",
        "        'best_epoch': 0,\n",
        "        'test_metrics': None\n",
        "    }\n",
        "\n",
        "    # Initialize early stopping and checkpoint for this fold\n",
        "    early_stopping = EarlyStopping(\n",
        "        patience=config.early_stopping_patience,\n",
        "        mode='max',\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        save_dir=f'checkpoints/fold_{fold_num}',\n",
        "        metric_name='val_accuracy',\n",
        "        mode='max'\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Training loop\n",
        "        for epoch in range(config.num_epochs):\n",
        "            # Train epoch\n",
        "            train_metrics = trainer.train_epoch(\n",
        "                train_loader,\n",
        "                unlabeled_loader,\n",
        "                epoch\n",
        "            )\n",
        "\n",
        "            # Validate\n",
        "            val_metrics = trainer.validate(val_loader)\n",
        "\n",
        "            # Update fold metrics\n",
        "            fold_metrics['train_metrics'].append(train_metrics)\n",
        "            fold_metrics['val_metrics'].append(val_metrics)\n",
        "\n",
        "            # Log metrics\n",
        "            logging.info(\n",
        "                f\"\\nFold {fold_num + 1}, Epoch {epoch + 1}/{config.num_epochs}\"\n",
        "            )\n",
        "            logging.info(f\"Train Metrics: {train_metrics}\")\n",
        "            logging.info(f\"Val Metrics: {val_metrics}\")\n",
        "\n",
        "            # Check for best model\n",
        "            if val_metrics['accuracy'] > fold_metrics['best_val_accuracy']:\n",
        "                fold_metrics['best_val_accuracy'] = val_metrics['accuracy']\n",
        "                fold_metrics['best_epoch'] = epoch\n",
        "\n",
        "                # Save checkpoint\n",
        "                checkpoint(\n",
        "                    trainer.model,\n",
        "                    val_metrics['accuracy'],\n",
        "                    epoch,\n",
        "                    {\n",
        "                        'train_metrics': train_metrics,\n",
        "                        'val_metrics': val_metrics\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            # Early stopping check\n",
        "            if early_stopping(val_metrics['accuracy'], trainer.model):\n",
        "                logging.info(\n",
        "                    f\"Early stopping triggered in fold {fold_num + 1} \"\n",
        "                    f\"at epoch {epoch + 1}\"\n",
        "                )\n",
        "                break\n",
        "\n",
        "        # Load best model for this fold\n",
        "        best_model_path = Path(f'checkpoints/fold_{fold_num}/best_model_val_accuracy.pth')\n",
        "        if best_model_path.exists():\n",
        "            checkpoint_data = torch.load(best_model_path, map_location=config.device, weights_only=False)\n",
        "            trainer.model.load_state_dict(checkpoint_data['model_state_dict'])\n",
        "            logging.info(\n",
        "                f\"Loaded best model from epoch {fold_metrics['best_epoch']} \"\n",
        "                f\"with validation accuracy {fold_metrics['best_val_accuracy']:.4f}\"\n",
        "            )\n",
        "\n",
        "        # Final validation on test set\n",
        "        test_metrics = trainer.validate(val_loader)\n",
        "        fold_metrics['test_metrics'] = test_metrics\n",
        "\n",
        "        # Calculate and log fold summary\n",
        "        fold_summary = calculate_fold_summary(fold_metrics)\n",
        "        log_fold_summary(fold_num, fold_summary)\n",
        "\n",
        "        # Plot fold-specific learning curves\n",
        "        plot_fold_learning_curves(\n",
        "            fold_metrics,\n",
        "            fold_num,\n",
        "            save_dir=f'results/fold_{fold_num}'\n",
        "        )\n",
        "\n",
        "        return fold_metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in fold {fold_num + 1} training: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def calculate_fold_summary(fold_metrics):\n",
        "    \"\"\"\n",
        "    Calculate summary statistics for a fold\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'best_val_accuracy': fold_metrics['best_val_accuracy'],\n",
        "        'best_epoch': fold_metrics['best_epoch'],\n",
        "        'final_test_metrics': fold_metrics['test_metrics'],\n",
        "        'training_time_epochs': len(fold_metrics['train_metrics']),\n",
        "        'convergence_metrics': {\n",
        "            'train_loss_final': fold_metrics['train_metrics'][-1]['loss'],\n",
        "            'val_loss_final': fold_metrics['val_metrics'][-1]['loss'],\n",
        "            'train_acc_final': fold_metrics['train_metrics'][-1]['accuracy'],\n",
        "            'val_acc_final': fold_metrics['val_metrics'][-1]['accuracy']\n",
        "        }\n",
        "    }\n",
        "\n",
        "def log_fold_summary(fold_num, fold_summary):\n",
        "    \"\"\"\n",
        "    Log summary of fold training\n",
        "    \"\"\"\n",
        "    logging.info(f\"\\nFold {fold_num + 1} Summary:\")\n",
        "    logging.info(f\"Best Validation Accuracy: {fold_summary['best_val_accuracy']:.4f}\")\n",
        "    logging.info(f\"Best Epoch: {fold_summary['best_epoch']}\")\n",
        "    logging.info(f\"Training Duration: {fold_summary['training_time_epochs']} epochs\")\n",
        "    logging.info(\"\\nFinal Test Metrics:\")\n",
        "    for metric, value in fold_summary['final_test_metrics'].items():\n",
        "        logging.info(f\"{metric}: {value:.4f}\")\n",
        "    logging.info(\"\\nConvergence Metrics:\")\n",
        "    for metric, value in fold_summary['convergence_metrics'].items():\n",
        "        logging.info(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "def plot_fold_learning_curves(fold_metrics, fold_num, save_dir):\n",
        "    \"\"\"\n",
        "    Plot learning curves for a specific fold\n",
        "\n",
        "    Args:\n",
        "        fold_metrics (dict): Metrics for the fold\n",
        "        fold_num (int): Fold number\n",
        "        save_dir (str): Directory to save plots\n",
        "    \"\"\"\n",
        "    save_dir = Path(save_dir)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Metrics to plot\n",
        "    metrics = ['loss', 'accuracy']\n",
        "\n",
        "    for metric in metrics:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Get metric values\n",
        "        train_values = [epoch[metric] for epoch in fold_metrics['train_metrics']]\n",
        "        val_values = [epoch[metric] for epoch in fold_metrics['val_metrics']]\n",
        "\n",
        "        # Plot training and validation curves\n",
        "        plt.plot(train_values, label=f'Train {metric}')\n",
        "        plt.plot(val_values, label=f'Validation {metric}')\n",
        "\n",
        "        # Mark best epoch\n",
        "        if metric == 'accuracy':\n",
        "            best_epoch = fold_metrics['best_epoch']\n",
        "            plt.axvline(x=best_epoch, color='r', linestyle='--',\n",
        "                       label=f'Best Epoch ({best_epoch})')\n",
        "\n",
        "        plt.title(f'Fold {fold_num + 1} - {metric.capitalize()} Learning Curve')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save plot\n",
        "        plt.savefig(save_dir / f'{metric}_curve_fold_{fold_num + 1}.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Plot additional metrics if available\n",
        "    additional_metrics = ['mask_mean', 'threshold']\n",
        "    for metric in additional_metrics:\n",
        "        if metric in fold_metrics['train_metrics'][0]:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            values = [epoch[metric] for epoch in fold_metrics['train_metrics']]\n",
        "            plt.plot(values, label=metric)\n",
        "            plt.title(f'Fold {fold_num + 1} - {metric.capitalize()} Evolution')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel(metric.capitalize())\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.savefig(save_dir / f'{metric}_evolution_fold_{fold_num + 1}.png')\n",
        "            plt.close()\n",
        "def analyze_kfold_results(fold_results, experiment):\n",
        "    \"\"\"\n",
        "    Analyze and visualize results from k-fold cross validation\n",
        "\n",
        "    Args:\n",
        "        fold_results (list): List of metrics from each fold\n",
        "        experiment (ExperimentManager): Experiment manager instance\n",
        "\n",
        "    Returns:\n",
        "        dict: Statistical summary of k-fold results\n",
        "    \"\"\"\n",
        "    # Create directory for k-fold results\n",
        "    kfold_dir = experiment.results_dir / 'kfold_analysis'\n",
        "    kfold_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Initialize containers for metrics\n",
        "    metrics_summary = {\n",
        "        'accuracy': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': [],\n",
        "        'loss': []\n",
        "    }\n",
        "\n",
        "    # Collect metrics from all folds\n",
        "    for fold_idx, fold_data in enumerate(fold_results):\n",
        "        logging.info(f\"\\nFold {fold_idx + 1} Results:\")\n",
        "        for metric, value in fold_data['test_metrics'].items():\n",
        "            if metric in metrics_summary:\n",
        "                metrics_summary[metric].append(value)\n",
        "                logging.info(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Calculate statistical summary\n",
        "    stats_summary = calculate_statistical_summary(metrics_summary)\n",
        "\n",
        "    # Plot fold comparisons\n",
        "    plot_fold_comparisons(metrics_summary, kfold_dir)\n",
        "\n",
        "    # Plot fold variations\n",
        "    plot_fold_variations(metrics_summary, kfold_dir)\n",
        "\n",
        "    # Save detailed results\n",
        "    save_kfold_results(metrics_summary, stats_summary, kfold_dir)\n",
        "\n",
        "    # Log summary statistics\n",
        "    log_statistical_summary(stats_summary)\n",
        "\n",
        "    return stats_summary\n",
        "\n",
        "def calculate_statistical_summary(metrics_summary):\n",
        "    \"\"\"\n",
        "    Calculate statistical measures for each metric\n",
        "    \"\"\"\n",
        "    stats_summary = {}\n",
        "\n",
        "    for metric, values in metrics_summary.items():\n",
        "        values = np.array(values)\n",
        "        stats_summary[metric] = {\n",
        "            'mean': np.mean(values),\n",
        "            'std': np.std(values),\n",
        "            'min': np.min(values),\n",
        "            'max': np.max(values),\n",
        "            'median': np.median(values),\n",
        "            'ci_95': np.percentile(values, [2.5, 97.5]).tolist()\n",
        "        }\n",
        "\n",
        "    return stats_summary\n",
        "\n",
        "def plot_fold_comparisons(metrics_summary, save_dir):\n",
        "    \"\"\"\n",
        "    Plot comparison of metrics across folds using box plots\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for idx, (metric, values) in enumerate(metrics_summary.items(), 1):\n",
        "        plt.subplot(2, 3, idx)\n",
        "        sns.boxplot(data=values)\n",
        "        plt.title(f'{metric.capitalize()} Distribution')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_dir / 'fold_comparisons.png')\n",
        "    plt.close()\n",
        "\n",
        "def plot_fold_variations(metrics_summary, save_dir):\n",
        "    \"\"\"\n",
        "    Plot variations of metrics across folds using line plots\n",
        "    \"\"\"\n",
        "    num_folds = len(next(iter(metrics_summary.values())))\n",
        "    fold_indices = range(num_folds)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for metric, values in metrics_summary.items():\n",
        "        plt.plot(fold_indices, values, 'o-', label=metric.capitalize())\n",
        "\n",
        "    plt.xlabel('Fold')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.title('Metric Variations Across Folds')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.savefig(save_dir / 'fold_variations.png')\n",
        "    plt.close()\n",
        "\n",
        "def save_kfold_results(metrics_summary, stats_summary, save_dir):\n",
        "    \"\"\"\n",
        "    Save detailed k-fold results to JSON\n",
        "    \"\"\"\n",
        "    results = {\n",
        "        'metrics_by_fold': {\n",
        "            metric: values for metric, values in metrics_summary.items()\n",
        "        },\n",
        "        'statistical_summary': stats_summary\n",
        "    }\n",
        "\n",
        "    with open(save_dir / 'kfold_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "def log_statistical_summary(stats_summary):\n",
        "    \"\"\"\n",
        "    Log statistical summary of k-fold results\n",
        "    \"\"\"\n",
        "    logging.info(\"\\nK-Fold Cross Validation Summary:\")\n",
        "\n",
        "    for metric, stats in stats_summary.items():\n",
        "        logging.info(f\"\\n{metric.capitalize()}:\")\n",
        "        logging.info(f\"Mean ± Std: {stats['mean']:.4f} ± {stats['std']:.4f}\")\n",
        "        logging.info(f\"Range: [{stats['min']:.4f}, {stats['max']:.4f}]\")\n",
        "        logging.info(f\"Median: {stats['median']:.4f}\")\n",
        "        logging.info(f\"95% CI: [{stats['ci_95'][0]:.4f}, {stats['ci_95'][1]:.4f}]\")\n",
        "\n",
        "def generate_kfold_report(fold_results, save_dir):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive report of k-fold results\n",
        "    \"\"\"\n",
        "    save_dir = Path(save_dir)\n",
        "    report = [\"# K-Fold Cross Validation Report\\n\"]\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    metrics_summary = {\n",
        "        metric: [fold['test_metrics'][metric] for fold in fold_results]\n",
        "        for metric in fold_results[0]['test_metrics'].keys()\n",
        "    }\n",
        "    stats_summary = calculate_statistical_summary(metrics_summary)\n",
        "\n",
        "    # Add overall summary\n",
        "    report.append(\"## Overall Performance\\n\")\n",
        "    for metric, stats in stats_summary.items():\n",
        "        report.append(f\"### {metric.capitalize()}\\n\")\n",
        "        report.append(f\"- Mean ± Std: {stats['mean']:.4f} ± {stats['std']:.4f}\")\n",
        "        report.append(f\"- Range: [{stats['min']:.4f}, {stats['max']:.4f}]\")\n",
        "        report.append(f\"- Median: {stats['median']:.4f}\")\n",
        "        report.append(f\"- 95% CI: [{stats['ci_95'][0]:.4f}, {stats['ci_95'][1]:.4f}]\\n\")\n",
        "\n",
        "    # Add per-fold details\n",
        "    report.append(\"## Per-fold Performance\\n\")\n",
        "    for fold_idx, fold_data in enumerate(fold_results):\n",
        "        report.append(f\"### Fold {fold_idx + 1}\\n\")\n",
        "        report.append(\"#### Test Metrics\")\n",
        "        for metric, value in fold_data['test_metrics'].items():\n",
        "            report.append(f\"- {metric}: {value:.4f}\")\n",
        "        report.append(\"\\n#### Training Summary\")\n",
        "        report.append(f\"- Best Epoch: {fold_data['best_epoch']}\")\n",
        "        report.append(f\"- Best Validation Accuracy: {fold_data['best_val_accuracy']:.4f}\\n\")\n",
        "\n",
        "    # Save report\n",
        "    with open(save_dir / 'kfold_report.md', 'w') as f:\n",
        "        f.write('\\n'.join(report))\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main training loop\n",
        "    \"\"\"\n",
        "    # Initialize experiment\n",
        "    config = Config()\n",
        "    experiment = ExperimentManager(config)\n",
        "\n",
        "    try:\n",
        "        # Load data\n",
        "        dataloaders = get_stl10_dataloaders(config)\n",
        "        logging.info(\"Data loaded successfully\")\n",
        "\n",
        "        # Initialize model and trainer\n",
        "        model, epaas_loss, supervised_loss = initialize_model(config)\n",
        "        trainer = Trainer(model, epaas_loss, supervised_loss, config)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(config.num_epochs):\n",
        "            # Train epoch\n",
        "            train_metrics = trainer.train_epoch(\n",
        "                dataloaders['train'],\n",
        "                dataloaders['unlabeled'],\n",
        "                epoch\n",
        "            )\n",
        "\n",
        "            # Validate\n",
        "            val_metrics = trainer.validate(dataloaders['val'])\n",
        "\n",
        "            # Update training history\n",
        "            experiment.training_history['train_metrics'].append(train_metrics)\n",
        "            experiment.training_history['val_metrics'].append(val_metrics)\n",
        "\n",
        "            # Log metrics\n",
        "            logging.info(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n",
        "            logging.info(f\"Train Metrics: {train_metrics}\")\n",
        "            logging.info(f\"Val Metrics: {val_metrics}\")\n",
        "\n",
        "            # Check for best model\n",
        "            if val_metrics['accuracy'] > experiment.training_history['best_val_accuracy']:\n",
        "                experiment.training_history['best_val_accuracy'] = val_metrics['accuracy']\n",
        "                experiment.training_history['best_epoch'] = epoch\n",
        "                trainer.checkpoint(model, val_metrics['accuracy'], epoch, val_metrics)\n",
        "\n",
        "            # Early stopping check\n",
        "            if trainer.early_stopping(val_metrics['accuracy'], model):\n",
        "                logging.info(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "        # Load best model for final evaluation\n",
        "        best_model_path = Path('checkpoints') / 'best_model_val_accuracy.pth'\n",
        "        try:\n",
        "          checkpoint = torch.load(best_model_path, map_location=config.device, weights_only=False)  # Modified lin\n",
        "          model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        except Exception as e:\n",
        "          logging.error(f\"Error loading best model: {str(e)}\")\n",
        "          raise\n",
        "\n",
        "        # Final evaluation on test set\n",
        "        test_metrics = trainer.validate(dataloaders['test'])\n",
        "        logging.info(f\"\\nFinal Test Metrics: {test_metrics}\")\n",
        "\n",
        "        # Get predictions for confusion matrix\n",
        "        true_labels = []\n",
        "        predictions = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloaders['test']:\n",
        "                inputs = inputs.to(config.device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = outputs.max(1)\n",
        "                true_labels.extend(targets.numpy())\n",
        "                predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "        # Plot results\n",
        "        experiment.plot_training_curves()\n",
        "        experiment.plot_confusion_matrix(true_labels, predictions)\n",
        "\n",
        "        # Save results\n",
        "        experiment.save_results(test_metrics)\n",
        "\n",
        "        return model, test_metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in training: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def run_k_fold_training():\n",
        "    \"\"\"\n",
        "    Run k-fold cross validation\n",
        "    \"\"\"\n",
        "    config = Config()\n",
        "    experiment = ExperimentManager(config, \"EPAAS_STL10_KFold\")\n",
        "\n",
        "    try:\n",
        "        # Load data\n",
        "        dataloaders = get_stl10_dataloaders(config)\n",
        "        dataset = dataloaders['train'].dataset\n",
        "\n",
        "        kfold = KFold(n_splits=config.num_folds, shuffle=True, random_state=SEED)\n",
        "        fold_results = []\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "            logging.info(f\"\\nStarting Fold {fold+1}/{config.num_folds}\")\n",
        "\n",
        "            # Create fold-specific dataloaders\n",
        "            train_subsampler = SubsetRandomSampler(train_idx)\n",
        "            val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "            train_loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=config.batch_size,\n",
        "                sampler=train_subsampler,\n",
        "                num_workers=config.num_workers\n",
        "            )\n",
        "            val_loader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=config.batch_size,\n",
        "                sampler=val_subsampler,\n",
        "                num_workers=config.num_workers\n",
        "            )\n",
        "\n",
        "            # Initialize model and trainer for this fold\n",
        "            model, epaas_loss, supervised_loss = initialize_model(config)\n",
        "            trainer = Trainer(model, epaas_loss, supervised_loss, config)\n",
        "\n",
        "            # Train fold\n",
        "            fold_metrics = train_fold(\n",
        "                trainer,\n",
        "                train_loader,\n",
        "                val_loader,\n",
        "                dataloaders['unlabeled'],\n",
        "                config,\n",
        "                fold\n",
        "            )\n",
        "\n",
        "            fold_results.append(fold_metrics)\n",
        "\n",
        "        # Analyze k-fold results\n",
        "        analyze_kfold_results(fold_results, experiment)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in k-fold training: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run main training\n",
        "    model, metrics = main()\n",
        "\n",
        "    # Optionally run k-fold validation\n",
        "    run_k_fold_training()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4VQOuiA_fwQ",
        "outputId": "b1afa8e9-b098-489d-8753-bc46ff581bc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-15 02:47:00,106 - INFO - Starting experiment: EPAAS_STL10\n",
            "INFO:EPAAS_STL10:Starting experiment: EPAAS_STL10\n",
            "2025-04-15 02:47:00,527 - INFO - Config: {'num_classes': 10, 'batch_size': 64, 'num_epochs': 5, 'base_lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'num_workers': 2, 'device': device(type='cuda'), 'initial_threshold': 0.95, 'final_threshold': 0.8, 'temperature': 1.0, 'alpha': 0.5, 'beta': 1.0, 'num_folds': 5, 'early_stopping_patience': 10, 'gradient_clip_val': 1.0}\n",
            "INFO:EPAAS_STL10:Config: {'num_classes': 10, 'batch_size': 64, 'num_epochs': 5, 'base_lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'num_workers': 2, 'device': device(type='cuda'), 'initial_threshold': 0.95, 'final_threshold': 0.8, 'temperature': 1.0, 'alpha': 0.5, 'beta': 1.0, 'num_folds': 5, 'early_stopping_patience': 10, 'gradient_clip_val': 1.0}\n",
            "Epoch 0: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it, loss=16.3, sup_loss=8.66, mask_mean=tensor(0.7344, device='cuda:0')]\n",
            "Epoch 1: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it, loss=13.5, sup_loss=7.02, mask_mean=tensor(0.7969, device='cuda:0')]\n",
            "Epoch 2: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it, loss=11.2, sup_loss=5.21, mask_mean=tensor(0.7969, device='cuda:0')]\n",
            "Epoch 3: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it, loss=10.7, sup_loss=4.87, mask_mean=tensor(0.7344, device='cuda:0')]\n",
            "Epoch 4: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it, loss=11.4, sup_loss=5.76, mask_mean=tensor(0.7656, device='cuda:0')]\n",
            "2025-04-15 02:56:40,170 - ERROR - Failed to save results: Object of type device is not JSON serializable\n",
            "ERROR:EPAAS_STL10:Failed to save results: Object of type device is not JSON serializable\n",
            "2025-04-15 02:56:40,306 - INFO - Starting experiment: EPAAS_STL10_KFold\n",
            "INFO:EPAAS_STL10_KFold:Starting experiment: EPAAS_STL10_KFold\n",
            "2025-04-15 02:56:40,309 - INFO - Config: {'num_classes': 10, 'batch_size': 64, 'num_epochs': 5, 'base_lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'num_workers': 2, 'device': device(type='cuda'), 'initial_threshold': 0.95, 'final_threshold': 0.8, 'temperature': 1.0, 'alpha': 0.5, 'beta': 1.0, 'num_folds': 5, 'early_stopping_patience': 10, 'gradient_clip_val': 1.0}\n",
            "INFO:EPAAS_STL10_KFold:Config: {'num_classes': 10, 'batch_size': 64, 'num_epochs': 5, 'base_lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0005, 'num_workers': 2, 'device': device(type='cuda'), 'initial_threshold': 0.95, 'final_threshold': 0.8, 'temperature': 1.0, 'alpha': 0.5, 'beta': 1.0, 'num_folds': 5, 'early_stopping_patience': 10, 'gradient_clip_val': 1.0}\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=18, sup_loss=8.96, mask_mean=tensor(0.7812, device='cuda:0')]\n",
            "Epoch 1: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14.2, sup_loss=8.12, mask_mean=tensor(0.6562, device='cuda:0')]\n",
            "Epoch 2: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14.9, sup_loss=7.08, mask_mean=tensor(0.7500, device='cuda:0')]\n",
            "Epoch 3: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=13.3, sup_loss=6.47, mask_mean=tensor(0.7656, device='cuda:0')]\n",
            "Epoch 4: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it, loss=14.9, sup_loss=7.19, mask_mean=tensor(0.8438, device='cuda:0')]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: 100%|██████████| 50/50 [01:17<00:00,  1.56s/it, loss=14.8, sup_loss=8.11, mask_mean=tensor(0.6875, device='cuda:0')]\n",
            "Epoch 1: 100%|██████████| 50/50 [01:17<00:00,  1.56s/it, loss=15.8, sup_loss=8.16, mask_mean=tensor(0.7812, device='cuda:0')]\n",
            "Epoch 2: 100%|██████████| 50/50 [01:17<00:00,  1.56s/it, loss=13.7, sup_loss=6.11, mask_mean=tensor(0.7188, device='cuda:0')]\n",
            "Epoch 3: 100%|██████████| 50/50 [01:18<00:00,  1.56s/it, loss=15.4, sup_loss=6.48, mask_mean=tensor(0.7656, device='cuda:0')]\n",
            "Epoch 4: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14, sup_loss=6.36, mask_mean=tensor(0.8438, device='cuda:0')]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it, loss=17, sup_loss=9, mask_mean=tensor(0.7188, device='cuda:0')]\n",
            "Epoch 1: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=15.3, sup_loss=8.34, mask_mean=tensor(0.6875, device='cuda:0')]\n",
            "Epoch 2: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14.9, sup_loss=6.99, mask_mean=tensor(0.7656, device='cuda:0')]\n",
            "Epoch 3: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=12.9, sup_loss=5.76, mask_mean=tensor(0.8125, device='cuda:0')]\n",
            "Epoch 4: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14.8, sup_loss=7.27, mask_mean=tensor(0.7812, device='cuda:0')]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it, loss=17.6, sup_loss=8.61, mask_mean=tensor(0.7656, device='cuda:0')]\n",
            "Epoch 1: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it, loss=16.5, sup_loss=8.17, mask_mean=tensor(0.7656, device='cuda:0')]\n",
            "Epoch 2: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it, loss=12.2, sup_loss=5.4, mask_mean=tensor(0.7031, device='cuda:0')]\n",
            "Epoch 3: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14, sup_loss=6.54, mask_mean=tensor(0.8125, device='cuda:0')]\n",
            "Epoch 4: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=15.3, sup_loss=8.24, mask_mean=tensor(0.8281, device='cuda:0')]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 0: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=14.7, sup_loss=8.08, mask_mean=tensor(0.7500, device='cuda:0')]\n",
            "Epoch 1: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=17.3, sup_loss=8.76, mask_mean=tensor(0.6562, device='cuda:0')]\n",
            "Epoch 2: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=18.6, sup_loss=9.27, mask_mean=tensor(0.7812, device='cuda:0')]\n",
            "Epoch 3: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it, loss=13.3, sup_loss=5.6, mask_mean=tensor(0.7969, device='cuda:0')]\n",
            "Epoch 4: 100%|██████████| 50/50 [01:17<00:00,  1.55s/it, loss=12.5, sup_loss=5.95, mask_mean=tensor(0.7969, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Y4S1HtKBB24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}